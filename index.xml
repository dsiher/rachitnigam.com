<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rachit Nigam on Rachit Nigam</title>
    <link>/</link>
    <description>Recent content in Rachit Nigam on Rachit Nigam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;&amp;nbsp;Rachit Nigam 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title></title>
      <link>/news/futil-asplos/</link>
      <pubDate>Wed, 18 Nov 2020 15:52:37 -0500</pubDate>
      
      <guid>/news/futil-asplos/</guid>
      <description>&lt;p&gt;Paper on &lt;a href=&#34;https://github.com/cucapra/futil/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Calyx&lt;/a&gt; accepted to &lt;a href=&#34;https://asplos-conference.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ASPLOS 2021&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/dios-asplos/</link>
      <pubDate>Wed, 18 Nov 2020 15:51:33 -0500</pubDate>
      
      <guid>/news/dios-asplos/</guid>
      <description>&lt;p&gt;Paper on &lt;a href=&#34;https://github.com/cucapra/diospyros&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Diospyros&lt;/a&gt; accepted to &lt;a href=&#34;https://asplos-conference.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ASPLOS 2021&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/oopsla-aec/</link>
      <pubDate>Mon, 14 Sep 2020 15:00:32 -0400</pubDate>
      
      <guid>/news/oopsla-aec/</guid>
      <description>&lt;p&gt;Member of the OOPSLA 2020 &lt;a href=&#34;https://2020.splashcon.org/track/splash-2020-Artifacts&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Artifact Evaluation Committee&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/dahlia-talks/</link>
      <pubDate>Thu, 28 May 2020 19:03:28 -0400</pubDate>
      
      <guid>/news/dahlia-talks/</guid>
      <description>&lt;p&gt;Presented Dahlia at PLDI &amp;lsquo;20, University of Washington, University of California Berkeley, Imperial College London and Stanford University.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Synthesis-Aided Compiler for DSP Architectures </title>
      <link>/publication/dios-wip/</link>
      <pubDate>Sat, 25 Apr 2020 22:13:28 -0400</pubDate>
      
      <guid>/publication/dios-wip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Compiling for the Reconfigurable Future</title>
      <link>/post/reconf-future/</link>
      <pubDate>Thu, 16 Apr 2020 11:59:11 -0400</pubDate>
      
      <guid>/post/reconf-future/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;A TLDR on why you should care.&lt;/strong&gt; FPGAs, a form of reconfigurable
architectures, already power a large number of datacenter applications. With
FPGA acceleration becoming mainstream, it is the perfect opportunity to think
about programming models for designing next-generation high-performance
hardware.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Moore&amp;rsquo;s law is in its death throes. With Global Foundries &lt;a href=&#34;https://www.anandtech.com/show/13277/globalfoundries-stops-all-7nm-development&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;announcing&lt;/a&gt;
that they are no longer pursuing 7nm production nodes, fabrication companies
focusing on &lt;a href=&#34;https://www.anandtech.com/show/15217/intels-manufacturing-roadmap-from-2019-to-2029&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;incremental improvements&lt;/a&gt;, and the end of the
arguably more important &lt;a href=&#34;https://en.wikipedia.org/wiki/Dennard_scaling&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Dennard scaling&lt;/a&gt;, we&amp;rsquo;re entering a new
era where general purpose architectures are no longer the solution.
Reconfigurable architectures are one of the hottest research topics and perhaps
hold the key to application-specific hardware acceleration. However, without
a sane programming model, reconfigurable architectures might not achieve the
success they deserve.&lt;/p&gt;

&lt;h3 id=&#34;reconfigurable-architectures&#34;&gt;Reconfigurable Architectures&lt;/h3&gt;

&lt;p&gt;Since the dawn of computer architecture, we&amp;rsquo;ve focused on building processors
that are good at executing &lt;em&gt;every&lt;/em&gt; conceivable program. The advances in
pipelined designs, speculative and out-of-order execution all try to
dynamically discover regularity and parallelism in arbitrary programs and
execute them as fast as possible. The performance benefits of these technologies
are inarguable. However, all good things come at a price. In their
single-minded zealotry to improve single threaded performance, processors introduce
an incredible amount of &lt;em&gt;control overhead&lt;/em&gt;. Figure 1 shows the energy
breakdown of executing an add instruction. The control dominates the cost of
executing an instruction.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;figure&gt;
&lt;img src=&#34;./img/energy-breakdown.png&#34;
     alt=&#34;Energy breakdown of executing an add instruction on 45nm technology.&#34;&gt;
&lt;/img&gt;
&lt;figcaption&gt;
Fig 1.
Energy breakdown of executing an add instruction from
&amp;ldquo;&lt;a href=&#34;https://ieeexplore.ieee.org/document/6757323&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Computing&amp;rsquo;s Energy Problem&lt;/a&gt;&amp;rdquo; [Horowitz, 2014].
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So while modern processors
can execute arbitrary programs quickly, they leave a lot of room for improvement
with an individual program.
Instead of paying for the cost of the general control structures in every program,
what if your processor could pay for the exactly the amount of control required
to execute the current program.
What if you
could &lt;em&gt;reconfigure&lt;/em&gt; your architecture
based on the currently executing program?
Reconfigurable architectures refers to the general class of architectures
that allow some degree of application-specific reconfigurability. The term
&amp;ldquo;reconfigurable architectures&amp;rdquo; is incredibly broad and spans everything from
the reconfigurability of meshes in &lt;a href=&#34;http://opencelerity.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;massive many-cores&lt;/a&gt; to bit-level
reconfigurable architectures. In this post, we&amp;rsquo;ll be focusing on Field
Programmable Gate Arrays (FPGAs) as a reconfigurable accelerator.&lt;/p&gt;

&lt;h3 id=&#34;fpgas-as-computational-accelerators&#34;&gt;FPGAs as Computational Accelerators&lt;/h3&gt;

&lt;p&gt;FPGAs were initially developed as high-performance simulators for circuit
designs. Testing a hardware design requires simulating its behavior over
thousands of clock cycles. With larger and more complex, the computational
power required to simulate and track the state of a design becomes increasingly
hard. Unfortunately, simulating a hardware design on a traditional processor
does not scale&amp;mdash;imagine trying to simulate an i3
processor on a Pentium 4. FPGAs were designed as simulation accelerators. They
provide &lt;em&gt;bit-level&lt;/em&gt; reconfigurability which allows them to simulate wires and
gates in a hardware design.&lt;/p&gt;

&lt;p&gt;The bit-level reconfigurability also made FPGAs
viable as a cheaper, low-volume alternate to application specific integrated
circuits (ASICs). Instead of taping-out custom chips, FPGAs could be used to
prototype and integrate such accelerators without paying for a full
silicon tape-out. In domains like
signal processing or networking, where real-time deadlines really matter and
CPUs struggle to meet high-throughput requirements, FPGAs were successfully
used as computational accelerators. The common thread in all of these use cases
is that we really want to design custom circuits but don&amp;rsquo;t want to pay the
costs of producing a whole new chip.&lt;/p&gt;

&lt;p&gt;FPGAs happily chugged along in these niche roles for a long time without taking
off in a big way. Researchers knew that FPGAs could play a big role as flexible
accelerators but didn&amp;rsquo;t have a &amp;ldquo;killer app&amp;rdquo;. Between 2010-2016, an exceptional
team of computer architects demonstrated
that FPGAs could be used as
computational accelerators &lt;em&gt;inside datacenters&lt;/em&gt; through the &lt;a href=&#34;https://www.microsoft.com/en-us/research/project/project-catapult/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Catapult&lt;/a&gt;
project. Catapult, and its successor &lt;a href=&#34;https://www.microsoft.com/en-us/research/project/project-brainwave/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;BrainWave&lt;/a&gt;, showed that not only can
FPGAs significantly improve the performance of modern large-scale applications,
they provide enough flexibility to be used in multiple domains, accelerating
everything from Bing search, Azure cloud network, and most recently, ML models.&lt;/p&gt;

&lt;p&gt;Other cloud services like AWS have jumped on this trend and now offer &lt;a href=&#34;https://aws.amazon.com/education/F1-instances-for-educators/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;F1
instances&lt;/a&gt; which provide access to high-end FPGA units through AWS&amp;rsquo;s
pay-what-you-use model.&lt;/p&gt;

&lt;h3 id=&#34;fpga-programming-101&#34;&gt;FPGA Programming 101&lt;/h3&gt;

&lt;p&gt;Owing to its root as a hardware simulator, FPGA programming toolchains repurpose
existing hardware design languages (HDLs). As a circuit simulator, this is
a really good idea. You can simply take your preexisting hardware design and
run it on an FPGA.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, when trying to run high-level application code
the level of abstraction afforded by HDLs is far too low-level.
Imagine
trying to write a convolution kernel by specifying every wire connection
into every adder and the computation that occurs at every clock cycle. Proponents
of HDLs will point out that we can eek out every bit of performance from a
low-level hardware design. However, this also means that design iteration times
are much worse. It can take many weeks of engineering effort to implement
and optimize a design.&lt;/p&gt;

&lt;p&gt;I am by no means the first person to point this productivity-performance
trade-off. Practitioners and researchers have created a multitude of
HDLs to improve the level of abstraction: &lt;a href=&#34;https://bluespec.com/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;BlueSpec&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/SystemVerilog&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;SystemVerilog&lt;/a&gt;, &lt;a href=&#34;https://github.com/cornell-brg/pymtl3&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;PyMTL&lt;/a&gt;,
&lt;a href=&#34;https://www.chisel-lang.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Chisel&lt;/a&gt;, etc. all aim to use host languages to improve the level of abstraction
in some manner. For example, Chisel is embedded in Scala and provides
modularity and parameterization mechanisms using Scala&amp;rsquo;s type system.
However, HDLs still &lt;em&gt;fundamentally&lt;/em&gt; operate at the gate-and-wire
level of abstraction. Chisel designs, after being typechecked by the Scala
compiler, are expanded into a structural specification of the hardware design.&lt;/p&gt;

&lt;p&gt;A more radical technique to lift the level of abstraction would be to specify
&lt;em&gt;how&lt;/em&gt; the computation occurs and use a compiler to generate the hardware for
that specification. The architecture community has been exploring the idea
of transforming behavioral (or functional) descriptions of computation
into hardware designs. This is commonly referred to High-Level Synthesis (HLS)
in the community.&lt;/p&gt;

&lt;h3 id=&#34;high-level-synthesis&#34;&gt;High-Level Synthesis&lt;/h3&gt;

&lt;p&gt;High-Level Synthesis&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; is the idea of compiling a computational description
in a high-level programming language&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;, like C or C++, into an HDL like
Verilog. HLS has been quite successful in a multitude of domains&amp;mdash;everything
from &lt;a href=&#34;https://ieeexplore.ieee.org/document/1466178&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;digital signal processing&lt;/a&gt; to &lt;a href=&#34;https://dl.acm.org/doi/10.1145/3020078.3021741&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;machine learning
accelerators&lt;/a&gt; has been implemented in HLS.&lt;/p&gt;

&lt;p&gt;The semantic gap between a functional description and timed hardware structures
is quite large. Hardware designs are &lt;em&gt;timed&lt;/em&gt; because they explicitly describe
the
behavior of individual circuits at the granularity of clock cycles. An HLS
compiler needs to transform the functional description into a &lt;em&gt;data path&lt;/em&gt;,
which describes the hardware structures that perform computations, and
a &lt;em&gt;control path&lt;/em&gt;, which describes the computation performed by components every
cycle.&lt;/p&gt;

&lt;p&gt;The promise of transforming &lt;em&gt;any&lt;/em&gt; C++ program into hardware is absurd at its
face. C++ programs dynamically allocate memory, use complicated control
structures, and are notoriously hard to analyze. Compare this to physical
hardware where memory sizes and control structures need to statically generated
at compile time.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll leave the specifics of where HLS fails for a future blog post. If you&amp;rsquo;re
curious, dive into &lt;a href=&#34;./files/pubs/dahlia.pdf&#34;&gt;our paper&lt;/a&gt; on &lt;a href=&#34;https://capra.cs.cornell.edu/dahlia&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Dahlia&lt;/a&gt; which identifies
some of these problems and shows how little bit of programming languages magic
can help.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re curious about this area, jump onto these cool blog posts and papers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.cornell.edu/~asampson/blog/fpgaabstraction.html&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;FPGAs Have the Wrong Abstraction&lt;/a&gt; by Adrian Sampson.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/5737854?tp=&amp;amp;arnumber=5737854&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;High-Level Synthesis for FPGAs: From Prototyping to Development&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/Cloud-Scale-Acceleration-Architecture.pdf&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;A Cloud-Scale Acceleration Architecture&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(If you&amp;rsquo;ve written a blog post on HLS-related stuff, email it to me so I can
add it here!)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks for &lt;a href=&#34;http://adriansampson.net&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Adrian Sampson&lt;/a&gt; and &lt;a href=&#34;https://www.cs.cornell.edu/~avh/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Alexa VanHattum&lt;/a&gt; for providing feedback on early
drafts of this blog post&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:2&#34;&gt;I apologize to my architect friends. Running designs on an FPGA in reality can be an incredible challenge. FPGAs have different kinds of memory and performance characteristics. Most hardware design codebases are carefully engineered to separate FPGA-specific design decisions from the core design.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Architects adopted the &amp;ldquo;Synthesis&amp;rdquo; terminology from hardware design workflows. A hardware design is &lt;em&gt;synthesized&lt;/em&gt; into silicon. Since we&amp;rsquo;re now generating designs from a high-level language, we&amp;rsquo;ll call it &amp;ldquo;High-level Synthesis&amp;rdquo;. From a compiler/programming languages viewpoint, this is just a compiler.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;The choice of C or C++ as a &amp;ldquo;high-level language&amp;rdquo; might seem odd but to architects, who operate at the level clock cycles and hardware structures, C++ is a huge jump in abstraction.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The First Two Years of My PhD</title>
      <link>/post/first-two-years/</link>
      <pubDate>Wed, 08 Apr 2020 00:40:17 -0400</pubDate>
      
      <guid>/post/first-two-years/</guid>
      <description>

&lt;p&gt;With the end of the Spring ’20 semester a month away, I have spent almost
two academic years at Cornell. A quick rundown of everything that happened:&lt;/p&gt;

&lt;h3 id=&#34;failures&#34;&gt;Failures&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Short paper on &lt;a href=&#34;https://github.com/cucapra/futil&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;FuTIL&lt;/a&gt; rejected from LCTES ’20.&lt;/li&gt;
&lt;li&gt;Rejected from Facebook fellowship ’20.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./publication/dahlia&#34;&gt;Dahlia&lt;/a&gt; rejected from ASPLOS ’20 with two weak rejects.&lt;/li&gt;
&lt;li&gt;Rejected from Microsoft research internship for summer ’19.&lt;/li&gt;
&lt;li&gt;Rejected from Qualcomm fellowship application ’19.&lt;/li&gt;
&lt;li&gt;Rejected from the Facebook fellowship ’19.&lt;/li&gt;
&lt;li&gt;Rejected from the Symantec fellowship ’19.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;successes&#34;&gt;Successes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Short paper on &lt;a href=&#34;https://github.com/cucapra/diospyros&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Diospyros&lt;/a&gt; accepted to LCTES ’20.&lt;/li&gt;
&lt;li&gt;Selected as a finalist for the Qualcomm fellowship ’20.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./publication/dahlia&#34;&gt;Dahlia&lt;/a&gt; accepted to PLDI ’20.&lt;/li&gt;
&lt;li&gt;Research internship at &lt;a href=&#34;https://research.fb.com/category/augmented-reality-virtual-reality/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Facebook Reality Labs&lt;/a&gt; for summer ’19.&lt;/li&gt;
&lt;li&gt;Gave an invited talk to the Princeton Architecture and PL groups.&lt;/li&gt;
&lt;li&gt;Organized the &lt;a href=&#34;https://www.cs.cornell.edu/courses/cs7194/2019sp/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Great works in PL&lt;/a&gt; seminar.&lt;/li&gt;
&lt;li&gt;Organized the programming languages retreat in Fall ’19.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;fall-18&#34;&gt;Fall ’18&lt;/h3&gt;

&lt;p&gt;I started at Cornell and was terrified that I would not be able to find an
advisor. I set up meetings with the PL faculty and Cornell and decided to
do a rotation with &lt;a href=&#34;http://adriansampson.net&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Adrian Sampson&lt;/a&gt; during the fall and switch to
working with &lt;a href=&#34;https://www.cs.cornell.edu/~jnfoster/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Nate Foster&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Adrian pitched me three projects: Use program synthesis
to automatically partition programs for reconfigurable architectures,
build a type system for a high-level programming language
for FPGAs, and a type system for graphics
and shader programming languages.&lt;/p&gt;

&lt;p&gt;I decided to work on the type system for FPGA programming (called Dahlia). I
was unsure that I would be a good fit for this project because I had no
background in computer architecture research. I hoped that my programming
languages experience would be useful for the project and that I could learn
enough about architecture to contribute to the project.&lt;/p&gt;

&lt;p&gt;I started reading about FPGAs, implementing various features for the Dahlia
compiler, and writing down proofs for various type system properties.
I also got involved with the programming languages group and gave my
&lt;a href=&#34;https://www.cs.cornell.edu/courses/cs7190/2018fa/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;first pldg talk&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We designed several language features for Dahlia. A particularly thorny
design issue was supporting complex iteration patterns while providing
type safety. We came up with &lt;a href=&#34;https://capra.cs.cornell.edu/seashell/docs/view.html&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;memory
views&lt;/a&gt; to solve this.
The design of views felt inelegant.&lt;/p&gt;

&lt;p&gt;I volunteered at OOPSLA ’19 in Boston where I met a lot of new and old
friends. I applied to industrial fellowships and was rejected from them.
Adrian said that they prefer to accept more senior students and that applying
was more important than being accepted. I agreed.&lt;/p&gt;

&lt;p&gt;During the semester I also realized that I was enjoying working on
Dahlia and asked Adrian to formally be my advisor. He agreed.&lt;/p&gt;

&lt;h3 id=&#34;winter-18&#34;&gt;Winter ’18&lt;/h3&gt;

&lt;p&gt;I went back to India for the winter break where I read a bunch of papers
and reviewed applications for PhD applicants. I convinced &lt;a href=&#34;https://www.cs.cornell.edu/~jnfoster/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Nate&lt;/a&gt; to
help me organize the &lt;a href=&#34;https://www.cs.cornell.edu/courses/cs7194/2019sp/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Great works in PL&lt;/a&gt; seminar as an excuse to
read classic PL papers.&lt;/p&gt;

&lt;h3 id=&#34;spring-19&#34;&gt;Spring ’19&lt;/h3&gt;

&lt;p&gt;I came back to Cornell and started implementing memory views in Dahlia.
I kept feeling that the OCaml codebase was slowing me down so I &lt;a href=&#34;https://github.com/cucapra/dahlia/pull/46&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;rewrote
Dahlia&lt;/a&gt; in Scala and implemented
memory views. The implementation demonstrated that views were inelegant
so we came up with a new implementation of memory views.&lt;/p&gt;

&lt;p&gt;Implementing views turned out to be a lot more challenging than I originally
expected and it took me four tries to get it right. Before the final attempt,
we realized there was a fundamental problem with checking views that we didn&amp;rsquo;t
know how to solve. I was feeling particularly down that day. During my
walk back home, I discovered an elegant solution for compositionally reasoning
about views.&lt;/p&gt;

&lt;p&gt;The biggest challenge with Dahlia was finding the right pitch for it.
We had some idea that it made hardware designs &amp;ldquo;more predictable&amp;rdquo; because
each language construct had a direct hardware mapping. However, we didn&amp;rsquo;t
know how to demonstrate this &amp;ldquo;predictability&amp;rdquo;. I was wary of qualitative
arguments. I spent the semester writing code and text. We started porting
an FPGA programming benchmark suite to Dahlia to see how it faired with larger
examples.&lt;/p&gt;

&lt;p&gt;In the background, I decided to do a summer internship that year and started
interviewed with MSR and Facebook Reality Labs (FRL). MSR rejected me and I
eventually accepted an offer from the silicon research team at FRL. I
also attended ASPLOS ’19 with Adrian and made a lot
of new architecture friends. Architects seemed to be livelier than PL
people because they&amp;rsquo;re living on the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Explicit_data_graph_execution&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;EDGE&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;summer-19&#34;&gt;Summer ’19&lt;/h3&gt;

&lt;p&gt;I spent my summer in Redmond at FRL using program synthesis to solve hardware
problems. Working on program synthesis is a roller coaster: the
solver gives you solutions and you&amp;rsquo;re happy. At some point it stops scaling
and you don&amp;rsquo;t know what to do anymore and everything is sad.&lt;/p&gt;

&lt;p&gt;I also wrote a few short sections for the Dahlia paper hoping to hit the
ASPLOS ’20 deadline.&lt;/p&gt;

&lt;h3 id=&#34;fall-19&#34;&gt;Fall ’19&lt;/h3&gt;

&lt;p&gt;My team at FRL sufficiently liked my project to ask me to continue working
on an offshoot. I realized that if I worked on a program synthesis project
alone, I would be sad all the time. I asked &lt;a href=&#34;https://www.cs.cornell.edu/~avh/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Alexa VanHattum&lt;/a&gt; if
she wanted to collaborate on it with me and she said yes.&lt;/p&gt;

&lt;p&gt;I flew back to Ithaca a week before the ASPLOS ’20 deadline fully expecting
to miss the deadline since we didn&amp;rsquo;t have a lot of content in the paper.
Adrian said we should hit the deadline so I switched gears into paper
writing mode. We wrote a paper in a week and submitted it to ASPLOS. I didn&amp;rsquo;t
expect the paper to get in because of a weak evaluation.&lt;/p&gt;

&lt;p&gt;A central problem with the evaluation was that it simply reimplemented C++
benchmarks in Dahlia which resulted in the same area and latency numbers
as the baselines. The evaluation didn&amp;rsquo;t say anything interesting about how
Dahlia enabled &amp;ldquo;predictable hardware design&amp;rdquo;&amp;mdash;which was the title of
our paper. I was starting to feel angsty about the project and felt like there
was no way evaluate it.&lt;/p&gt;

&lt;p&gt;I was burned out from the paper writing so I asked my friend &lt;a href=&#34;https://samginzburg.com/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Sam
Ginzburg&lt;/a&gt; to host me at Princeton for a week. He recommended that I
give a talk to the architecture group which was a great idea but destroyed
my plans of not working during the Princeton visit. I visited Princeton, gave
a talk, and met a lot of cool people. Sam was working on a measurement project
and had a lot of pretty graphs. I decided that the only way to calm my angst
with Dahlia was to perform measurements and quantify predictability. I did
not yet know how.&lt;/p&gt;

&lt;p&gt;I continued spending my time implementing the compiler and getting the
benchmarks running. During an auspicious trip to the Applications Driving
Architecture (ADA) symposium, I came up with a plan to show that Dahlia enabled
predictable design.&lt;/p&gt;

&lt;p&gt;The plan was as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Take a hardware design and enumerate all the design points.&lt;/li&gt;
&lt;li&gt;Run all the points and extract statistics (area and latency).&lt;/li&gt;
&lt;li&gt;Show that the subset of design points Dahlia accepts smoothly trade off
area for latency and are therefore &amp;ldquo;predictable&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Profit.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The challenging part of this plan was getting all the data. A back-of-the-envelope
calculation showed that we&amp;rsquo;d need a few months of compute time to
get all the data. I had, unfortunately, reached a point where I needed to
build a distributed experimentation framework.&lt;/p&gt;

&lt;p&gt;I got to work building the framework on top of an existing in-house benchmarking
server. It took me three weeks of relentless Python hacking to get multiple
AWS machines to run FPGA designs. Once we had that, pretty graphs started
rolling out and I started confirming various claims about Dahlia quantitatively.
Around this time, Dahlia was rejected from ASPLOS.&lt;/p&gt;

&lt;p&gt;While this was expected, I was still sad for a few days. We decided to resubmit
to PLDI. With three weeks to go, I ran the capstone
experiment: enumerate 32,000 points and run them on the 80 workers. I
calculated that it would take 5 days to finish the jobs. I ran into numerous
issues like &lt;code&gt;ls&lt;/code&gt; being too slow, job uploads taking three days, and monitoring
scripts DDoS-ing the servers. I babysat the servers, painfully restarting
dead workers and failed jobs, and eventually got the
results. The graphs looked pretty and validated Dahlia&amp;rsquo;s claims. I was very
tired but happy.&lt;/p&gt;

&lt;p&gt;During the last week while writing and finishing up the final experiments, I
started staying late in the office. Three days before the deadline (Nov 19),
I finished all the experiments and got cookies at midnight to celebrate this.
After the cookies, I decided to bike back to home. I
started biking down 2am. At 2.05am, I fell from my bike during a sharp turn
and broke my left wrist. My roommate took me the ER where I got a splint. I was heartbroken.&lt;/p&gt;

&lt;p&gt;I woke up the next day and went into the lab after getting a proper arm cast.
I could no longer type on a keyboard so I started handwriting the edits to
the paper which my co-authors then put into the paper. At 1am on November 23,
we &lt;a href=&#34;https://twitter.com/notypes/status/1198111419704717312&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;submitted&lt;/a&gt; the
Dahlia paper to PLDI ’20. I was unsure if the paper would get in but I was
proud of the work we had done.&lt;/p&gt;

&lt;p&gt;The semester rolled on and I started brainstorming ideas with Alexa and FRL
on a new project. We decided to use program synthesis to generate
high-performance kernels for DSPs.&lt;/p&gt;

&lt;h3 id=&#34;winter-19&#34;&gt;Winter ’19&lt;/h3&gt;

&lt;p&gt;I went back home to India to recuperate from the broken arm. I proposed
submitting a Qualcomm fellowship proposal for our DSP project. We quickly
hacked up a demo project (called &lt;a href=&#34;https://github.com/cucapra/diospyros&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Diospyros&lt;/a&gt;) and submitted the proposal.&lt;/p&gt;

&lt;h3 id=&#34;spring-20&#34;&gt;Spring ’20&lt;/h3&gt;

&lt;p&gt;I came back to Cornell in the spring. Doctor told me that while my broken wrist
bone had healed, a cartilage tear in my wrist might never properly heal. I
wondered if a paper submission was worth a lifelong injury (it wasn&amp;rsquo;t).&lt;/p&gt;

&lt;p&gt;The semester rolled on and we were accepted for stage 2 of the Qualcomm
proposal. We continued hacking on the project and wrote an even stronger stage 2
proposal with real graphs. Emboldened by the success, we also decided to write
a work-in-progress paper for LCTES ’20. In parallel, I joined another project
to build an intermediate language (called &lt;a href=&#34;https://github.com/cucapra/futil&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;FuTIL&lt;/a&gt;) for compiling high-level
languages to hardware circuits. I convinced my collaborators for that project
to submit an LCTES paper as well. We wrote two very good papers and submitted
them.&lt;/p&gt;

&lt;p&gt;In the meantime PLDI reviews came back and they were incredibly positive:
two strong accepts and two weak
accepts. Adrian said it was almost certainly enough to get into PLDI. We
wrote up a rebuttal and submitted it. Two weeks later, Dahlia was accepted
to PLDI ’20. Another week after the acceptance I submitted an artifact to
the PLDI artifact evaluation committee. I also volunteered for the committee
and reviewed some cool artifacts in the following weeks.&lt;/p&gt;

&lt;p&gt;I was generally happier about things, especially since I had published my first
grad school paper. However, at the start of March, everything turned upside
down. Due to the COVID-19 crisis, Cornell shut down its campus and PLDI
transformed into a virtual conference. I felt sad that I wouldn&amp;rsquo;t be able
to give a talk on Dahlia in paper. Sad enough to write a &lt;a href=&#34;./post/virtual-cs-conferences/&#34;&gt;blog
post&lt;/a&gt; about it.&lt;/p&gt;

&lt;p&gt;A few weeks into working from home and adjusting to our new reality, we heard
back from LCTES. The paper on Diospyros is accepted while the one on FuTIL is
rejected. We also hear back from Qualcomm saying that we made it to the final
stage.&lt;/p&gt;

&lt;h3 id=&#34;epilogue&#34;&gt;Epilogue&lt;/h3&gt;

&lt;p&gt;My first two years in grad school were a lot of expected and unexpected things.
The ups and downs of research were expected. The ups and downs of life were
not (injuries and global pandemics). This post leaves out a lot of my personal
accomplishments: I made a lot of friends, I took up biking and baking, I got
healthier, etc. Submitting my first paper was a big accomplishment for me but
I don&amp;rsquo;t I like the way I got to it. I sacrificed my personal health (due to
my own work ethic) and injured myself. Going forward, I want to set better
boundaries and think harder about the trade-offs between my life and my
research. I am grateful to the many people who made my first two years at
Cornell bearable.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/lctes-dios/</link>
      <pubDate>Tue, 07 Apr 2020 23:33:59 -0400</pubDate>
      
      <guid>/news/lctes-dios/</guid>
      <description>&lt;p&gt;Work-in-progress paper on &lt;a href=&#34;https://github.com/cucapra/diospyros&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Diospyros&lt;/a&gt; accepted to &lt;a href=&#34;https://conf.researchr.org/series/LCTES&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;LCTES&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/qualcomm-finalist/</link>
      <pubDate>Tue, 07 Apr 2020 23:30:26 -0400</pubDate>
      
      <guid>/news/qualcomm-finalist/</guid>
      <description>&lt;p&gt;Finalist for the &lt;a href=&#34;https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/2020-north-america&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Qualcomm Fellowship&lt;/a&gt; with &lt;a href=&#34;https://www.cs.cornell.edu/~avh/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Alexa VanHattum&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Cost of Virtualizing CS Conferences</title>
      <link>/post/virtual-cs-conferences/</link>
      <pubDate>Wed, 18 Mar 2020 23:15:05 -0400</pubDate>
      
      <guid>/post/virtual-cs-conferences/</guid>
      <description>

&lt;p&gt;Conferences in computer science are an odd occurrence. Unlike most other
research fields which primarily focus on publishing in journals, conferences
ended up being the primary publication and presentation venue in CS. They also
became the place where researchers network with each other,
learn about ongoing research, and drink beer with their grad school buddies.&lt;/p&gt;

&lt;p&gt;Because of this, conference presentations and networking play an incredibly
important part of a junior researcher&amp;rsquo;s career. Conferences allow us to show
our research to our community and have other people learn about us. In my field
of research, programming languages and systems, it takes anywhere between one
year to multiple years to complete a project. Add to that yearly deadlines and
specialized venues which results in a junior PhD student having anywhere from
two to four presentations before they go on the job market. Our recognition in
our community from our presentations and our papers is what gets us invitation
for interviews and job offers.&lt;/p&gt;

&lt;p&gt;Unfortunately, with the outbreak of &lt;a href=&#34;https://en.wikipedia.org/wiki/Coronavirus_disease_2019&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;COVID-19&lt;/a&gt;, our world has been turned
upside down. Beyond the incredible amounts of fear, uncertainty, and human
suffering it has caused, it has also destroyed one of the core mechanisms of
conducting science&amp;mdash;meeting people. Multiple major academic conferences
(&lt;a href=&#34;https://asplos-conference.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ASPLOS&lt;/a&gt;, &lt;a href=&#34;https://iclr.cc/Conferences/2020/virtual&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ICLR&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/PLDI/status/1240401711124090883&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;PLDI&lt;/a&gt;) have been canceled. Junior researchers, who had
decided to go on job markets, find internships, or visit another institutions
have had to cancel all of their plans. The impact of these things is
unquantifiable&amp;mdash;how does one measure the effect of a missed serendipitous
research collaboration, or that one person on a hiring committee hearing about
your work?&lt;/p&gt;

&lt;p&gt;However, I am not here to complain about missed conferences. Canceling
conferences in the midst of a global pandemic is &lt;em&gt;the right thing&lt;/em&gt; to do.
I instead want to figure out how we as a community can recreate the
opportunities that conferences create for us every year. I am not an expert in
this so I will need help. I have attempted to summarize the crucial
opportunities conferences give us, what the challenges of running a virtual
conferences are, and what options we have given that physical meetings are out
of the question for a while.&lt;/p&gt;

&lt;h3 id=&#34;goals-of-a-conference&#34;&gt;Goals of a conference&lt;/h3&gt;

&lt;p&gt;From my (second-year PhD student in a relatively small community) perspective,
conferences traditionally satisfy the following goals:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Dissemination of research&lt;/strong&gt;: The primary goal of any conference is to allow
researchers to present their work to their peers and discuss it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Welcoming new researchers&lt;/strong&gt;: The bloodline of our communities are new
researchers. From undergrads who are attending conferences for the first
time to PhD student presenting their research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The &amp;ldquo;Hallway&amp;rdquo; track&lt;/strong&gt;: Well understood to be the actual primary goal of
any conference, the hallway track is the colloquial name for researchers
hanging out with each other and discussing research and whatever else that
comes to their mind. It allows us to build long term connections within our
community.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;options-for-virtual-conferences&#34;&gt;Options for Virtual conferences&lt;/h3&gt;

&lt;p&gt;Given that most health organizations have recommended that non-essential
travel be suspended, our only choice is to have virtual conferences in some
format. Virtual formats present several challenges:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Multiple time-zones&lt;/strong&gt;: Since researchers are not directly traveling to
one physical location for the conference, it&amp;rsquo;s safe to assume they will
distributed across the world in different time-zones.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lack of commitment&lt;/strong&gt;: As a friend of mine put it, it&amp;rsquo;s hard to set aside
the time to interact with presenters (who are possibly remote) when there
are other commitments like teaching a class or having research meetings.
Physical conferences act as a forcing function to set this time aside.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Both of these problems are challenging to solve. Following are some proposals
I&amp;rsquo;ve seen discussed/implemented at currently canceled conferences.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Recorded presentations&lt;/strong&gt;: The bare minimum any conference can do to
satisfy the first goal is to have authors record research talks and upload
them to YouTube. This will allow researchers to reach out to the people who
are most interested in their work and already know about it, but not a wider
audience that a physical conference gives access to. It might also be
possible to welcome new researchers through videos but they&amp;rsquo;d likely feel
impersonal.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Chatrooms for discussing papers&lt;/strong&gt;: In addition to uploading all the talks
to YouTube, &lt;a href=&#34;https://asplos-conference.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ASPLOS 20&lt;/a&gt; created a Slack channel to discuss
each paper and co-located workshops. This improves the possibility of direct
interactions by making community members available in the same place.
Unfortunately, there really is no way of creating the hallway track in such
a setup. As a junior student, it might be hard or impossible to get
introductions to/talk to other researchers when they are not present in
person. Furthermore, because of the asynchronous nature of chatrooms, it
might be hard to have detailed conversations with people in different
timezones.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Livestreaming the conference&lt;/strong&gt;: Livestreaming the conference in real time
brings the experience as close to a conference session as possible. People
are required to commit time beforehand and ask questions to right after
a talk. Setting this up is non-trivial owing to time zone issues. Again,
while this provides the opportunity for more direct conversations, there
doesn&amp;rsquo;t seem to be a good way to recreate a hallway track.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Postpone the conference/Merge it with another&lt;/strong&gt;: The nuclear option of
pushing back the conference and waiting out the pandemic. By definition,
this will recreate the experience of a conference. However, this would be
incredibly hard to do since conferences are carefully planned to not overlap
with other conferences in relevant areas. A different approach might to be
have a bigger conference the next year and have papers from both &lt;em&gt;this year&lt;/em&gt;
and &lt;em&gt;next year&lt;/em&gt; be presented there. Again, I imagine this would be a
nightmare to organize. It also fundamentally cannot recreate opportunities
for researchers who go on the job market this year.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;None of the solutions here are perfect and I wouldn&amp;rsquo;t know which one to choose.
Each of these require hard trade-offs that we, as a community, have to make.
The lack of conferences and the opportunities they create is not measurable
which makes it easier to ignore their impact. I really hope that we can
come up with a solution that is cognizant of this and takes into consideration
the people most impacted by this.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A personal note&lt;/strong&gt;: I had &lt;a href=&#34;https://capra.cs.cornell.edu/dahlia&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;a paper&lt;/a&gt; accepted at PLDI 20. This
is my first first-author paper and I have been incredibly excited to present
this work for a really long time. I always imagined my first presentation
to an exciting and terrifying rite of passage that I would celebrate with
my friends, colleagues, and advisors. I feel a deep sense of loss, almost
as if all the hard work was &amp;ldquo;zeroed out&amp;rdquo; because I can&amp;rsquo;t present it anymore.
I assume other people in my situation feel similarly. I don&amp;rsquo;t know if senior
researchers put this much value in conference presentations (since they&amp;rsquo;ve
already given so many) but it seems important to acknowledge this feeling that
junior researchers have when we come up with solutions for virtual conferences.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/dahlia-pldi2020/</link>
      <pubDate>Sun, 01 Mar 2020 14:29:17 -0500</pubDate>
      
      <guid>/news/dahlia-pldi2020/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://capra.cs.cornell.edu/dahlia&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Dahlia&lt;/a&gt; was accepted to &lt;a href=&#34;http://conf.researchr.org/home/pldi-2020&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;PLDI 2020&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predictable Accelerator Design</title>
      <link>/publication/dahlia/</link>
      <pubDate>Mon, 03 Feb 2020 16:44:36 -0400</pubDate>
      
      <guid>/publication/dahlia/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/news/aec-pldi2020/</link>
      <pubDate>Sat, 01 Feb 2020 15:01:20 -0500</pubDate>
      
      <guid>/news/aec-pldi2020/</guid>
      <description>&lt;p&gt;Member of the PLDI 2020 &lt;a href=&#34;https://pldi20.sigplan.org/track/pldi-2020-PLDI-Research-Artifacts&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Artifact Evaluation Committee&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/dahlia-princeton/</link>
      <pubDate>Sun, 01 Sep 2019 15:02:33 -0500</pubDate>
      
      <guid>/news/dahlia-princeton/</guid>
      <description>&lt;p&gt;Gave an invited talk on Dahlia at Princeton.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/frl2019/</link>
      <pubDate>Wed, 01 May 2019 15:03:23 -0500</pubDate>
      
      <guid>/news/frl2019/</guid>
      <description>&lt;p&gt;Research intern at &lt;a href=&#34;https://www.facebook.com/careers/areas-of-work/facebookrealitylabs/?teams[0]=Facebook%20Reality%20Labs&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Facebook Reality Labs&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
