<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rachit Nigam on Rachit Nigam</title>
    <link>/</link>
    <description>Recent content in Rachit Nigam on Rachit Nigam</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;&amp;nbsp;Rachit Nigam 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Synthesis-Aided Compiler for DSP Architectures </title>
      <link>/publication/dios-wip/</link>
      <pubDate>Sat, 25 Apr 2020 22:13:28 -0400</pubDate>
      
      <guid>/publication/dios-wip/</guid>
      <description></description>
    </item>
    
    <item>
      <title>FPGA programming for the rest of us</title>
      <link>/post/predictable-accelerator-design/</link>
      <pubDate>Tue, 21 Apr 2020 11:33:43 -0400</pubDate>
      
      <guid>/post/predictable-accelerator-design/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;THIS IS A DRAFT POST. DO NOT DISTRIBUTE.&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This is quick overview of my research on &lt;a href=&#34;./publication/dahlia&#34;&gt;Dahlia&lt;/a&gt;, a
new programming language that leverages sub-structural types to make hardware
design predictable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This blog post assumes some familiarity with reconfigurable architectures and
High-Level Synthesis. If you want a quick overview on those, check out my
blog post on &lt;a href=&#34;./post/reconf-future&#34;&gt;compiling for the reconfigurable future&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;High-Level Synthesis (HLS) is the idea of transforming functional descriptions
of programs into performant and efficient hardware designs. The productivity
and accessibility benefits of raising the level of abstraction are remarkable.
For example, here is how you can implement a simple dot-product accelerator
(eliding some wrapper code required to generate communication interfaces):&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;mv_mult&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
  &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
  &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We have managed to implement a full accelerator in less than ten lines of code!
The HLS compiler will automatically generate the communication interfaces and
the required hardware modules. Owing to its incredible promise of rapid
iterative design, HLS tools are often marketed to software engineers.&lt;/p&gt;

&lt;p&gt;Unfortunately, building &lt;em&gt;performant&lt;/em&gt; designs in HLS is not as simple as writing
a dot-product accelerator. HLS tools use an incredible array of &lt;a href=&#34;https://dl.acm.org/doi/10.1145/1146909.1147025&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;analyses&lt;/a&gt;
and program transformations to generate efficient hardware. Add to this
closed source tools and long compilation cycles, we end up with black box tools that
fail to provide feedback when things go wrong. In order to force HLS to generate
desired hardware, HLS users often end up writing convoluted code that can
direct the compiler into making desired choices.&lt;/p&gt;

&lt;p&gt;Instead of performing code gymnastics, HLS programming models should provide
a principled mechanism to control various aspects, such as timing and resource
sharing, of the generated hardware.&lt;/p&gt;

&lt;h3 id=&#34;pitfalls-of-hls&#34;&gt;Pitfalls of HLS&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s walk through a short example to demonstrate the failings of HLS tools.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;We begin with everyone&amp;rsquo;s favorite kernel, General Matrix-Matrix Multiply (GeMM).
There are three good reasons to start by building a GeMM accelerator:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Along with convolution, GeMM forms the foundation of modern ML.&lt;/li&gt;
&lt;li&gt;The kernel has a lot of inherent parallelism.&lt;/li&gt;
&lt;li&gt;We already know how to build good GeMM accelerators by hand.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The HLS implementation for GeMM is straightforward:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
      &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;prod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The program looks like any GeMM implementation you&amp;rsquo;d expect to see in a freshmen
level course. HLS is particularly good at synthesizing such compute-heavy
loop-nests. The generated FPGA design is pretty reasonable&amp;mdash;it computes the
matrix product in 841ms, or about 10x faster than the same code running on
a CPU. The design occupies 2,355 of the FPGA&amp;rsquo;s lookup tables (LUTs). Remember
these two metrics: runtime and area (correlated to the number of LUTs) since
they are the primary objectives in a hardware design. Accelerator
design is all about maximizing this trade-off: An ideal hardware design
takes as little area as possible while running as fast as possible.&lt;/p&gt;

&lt;p&gt;Having a functional design isn&amp;rsquo;t sufficient. Next, we&amp;rsquo;d like to trade-off
area for runtime. The FPGA has well over a million LUTs and we&amp;rsquo;d like to
expend more area to get performance benefits. A straightforward way of
parallelizing the GeMM kernel is by running copies of the innermost loop in
parallel. HLS tools provide pragmas (or C annotations) that can tell the compiler
to duplicate a loop body:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;cp&#34;&gt;#pragma HLS unroll factor=8
&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;  &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;#pragma&lt;/code&gt; states that the innermost loop should run 8 copies in parallel
by &lt;em&gt;unrolling&lt;/em&gt; the loop. Logically, this is the same as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;8&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;...&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;where each statement in the loop body runs in parallel. Since we&amp;rsquo;re trading off
area for runtim, we should do our due diligence and make an &lt;em&gt;area-runtime&lt;/em&gt;
plot to see how spending more area improves our runtime. Since we&amp;rsquo;re performing
many computations in parallel, we expect our area numbers to go up while the
runtime numbers go down.&lt;/p&gt;

&lt;div class=&#39;row&#39;&gt;
&lt;div class=&#39;col-sm-6&#39;&gt;
&lt;img src=&#34;./img/no-partition-unrolling-runtime-avg.png&#34;
     alt=&#34;Runtime (ms) when unrolling innermost without any partitioning&#34;/&gt;
&lt;/div&gt;
&lt;div class=&#39;col-sm-6&#39;&gt;
&lt;img src=&#34;./img/no-partition-unrolling-lut-used.png&#34;
     alt=&#34;LUTs used when unrolling innermost without any partitioning&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#39;row&#39;&gt;
&lt;center&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;These numbers look odd. Our area seems to roughly increase as we increase the
unrolling factor but our runtime is all over the place. What is going on?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;On Physical Memories&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Real memory, much like the rest of a processor, is a physical circuit with
constraints on when and where it can process read and write requests. Modern
processors make it really easy and cheap to randomly access memory addresses
by using multiple levels of caches. FPGAs on the other hand expose memories
with a very low-level interface&amp;ndash;each memory is only allowed to read/write one
value every clock cycle.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Given this one read/write per cycle restriction, let&amp;rsquo;s think what our hardware
design is trying to do:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Each one of these statements try to access a unique address in &lt;code&gt;m1&lt;/code&gt; and &lt;code&gt;m2&lt;/code&gt;.
This means, that each clock cycle, memories &lt;code&gt;m1&lt;/code&gt; and &lt;code&gt;m2&lt;/code&gt; get &lt;strong&gt;8 read
requests&lt;/strong&gt; while being able to only service one request a cycle. HLS compilers
statically detect conflicting accesses and &lt;em&gt;stall&lt;/em&gt; the parallel reads to the
memories. So even though we&amp;rsquo;re spending area to create copies of our loop
body in the hardware, we don&amp;rsquo;t get to see any performance benefits.&lt;/p&gt;

&lt;p&gt;In order to get the performance benefits, we have to &lt;em&gt;partition&lt;/em&gt; our memories.
A partitioned memory can be accessed as one logical entity but is backed by
several physical memories containing disjoint elements. HLS tools can partition
memories using the partition pragma:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-C&#34; data-lang=&#34;C&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#pragma HLS ARRAY_PARTITION VARIABLE=m1 FACTOR=8
&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;512&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A memory partitioned by a factor of 8 is supported by 8 physical banks, each
containing a disjoint set of elements from the original array. Now that
our memories can support up to 8 parallel reads/writes, let&amp;rsquo;s see what our
graphs look like:&lt;/p&gt;

&lt;div class=&#39;row&#39;&gt;
&lt;div class=&#39;col-sm-6&#39;&gt;
&lt;img src=&#34;./img/const-partition-unroll-runtime-avg.png&#34;
     alt=&#34;Runtime (ms) when unrolling innermost with partitioning = 8&#34;/&gt;
&lt;/div&gt;
&lt;div class=&#39;col-sm-6&#39;&gt;
&lt;img src=&#34;./img/const-partition-unroll-lut-used.png&#34;
     alt=&#34;LUTs used when unrolling innermost with partitioning = 8&#34;/&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#39;row&#39;&gt;
&lt;center&gt;
&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Once again, the rough area trend goes up but the runtime numbers are still
all over the place. What&amp;rsquo;s worse, some of the unrolling factors seem to now
generate &lt;em&gt;invalid hardware designs&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TODO: explain this result.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;a-little-bit-of-pl-magic&#34;&gt;A Little Bit of PL magic&lt;/h3&gt;

&lt;p&gt;The fundamental problem here is that FPGA designs use &lt;em&gt;physical resources&lt;/em&gt;
without reasoning about their constraints. The HLS tools will happily generate
hardware for configurations that produce worse area and runtime numbers. Is
HLS a fundamentally a bad idea?&lt;/p&gt;

&lt;p&gt;I argue that beneath the mess of weird semantics and unpredictable behavior,
there is a reasonable programming model. The promise of HLS&amp;mdash;to make FPGA
programming accessible to us measly software programmers&amp;mdash;is an ambitious
goal and stands to truly revolutionize how we design heterogeneous systems.
Instead of giving up on the idea, perhaps we can separate out its successes
from its failures.&lt;/p&gt;

&lt;h3 id=&#34;p-stands-for-predictable&#34;&gt;P stands for Predictable&lt;/h3&gt;

&lt;p&gt;In our &lt;a href=&#34;./files/pubs/dahlia.pdf&#34;&gt;paper&lt;/a&gt;, we identified &lt;em&gt;predictability&lt;/em&gt; as a central goal
for HLS compilers. However, predictability is a subjective term&amp;mdash;as a reviewer
was quick to point out, &amp;ldquo;what is and isn&amp;rsquo;t predictable is matter of training,
background, documentation and support.&amp;rdquo; The examples above might make perfect
sense to a hardware designer&amp;mdash;after all, they are well versed with the
restrictions of physical memories. On the other hand, an experienced C++
programmer might find the above graphs totally baffling. We identified
area-latency trade-offs as the central predictability problem in HLS.
For us, predictability can be summarized as &amp;ldquo;If I spend more area, I get better
performance.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;The presented results use real data from synthesizing and running FPGA designs using &lt;a href=&#34;https://www.xilinx.com/products/design-tools/vivado/integration/esl-design.html&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Vivado HLS&lt;/a&gt; on &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/f1/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;AWS F1&lt;/a&gt; instances. Check out &lt;a href=&#34;./files/pubs/dahlia.pdf&#34;&gt;our paper&lt;/a&gt; for full details.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Real FPGA memories are slightly more complicated because they have several &lt;em&gt;memory ports&lt;/em&gt;. Each memory port allows one read/write every clock cycle.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Compiling for the Reconfigurable Future</title>
      <link>/post/reconf-future/</link>
      <pubDate>Thu, 16 Apr 2020 11:59:11 -0400</pubDate>
      
      <guid>/post/reconf-future/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;A TLDR on why you should care.&lt;/strong&gt; FPGAs, a form of reconfigurable
architectures, already power a large number of datacenter applications. With
FPGA acceleration becoming mainstream, it is the perfect opportunity to think
about programming models for designing next-generation high-performance
hardware.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Moore&amp;rsquo;s law is in its death throes. With Global Foundries &lt;a href=&#34;https://www.anandtech.com/show/13277/globalfoundries-stops-all-7nm-development&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;announcing&lt;/a&gt;
that they are no longer pursuing 7nm production nodes, fabrication companies
focusing on &lt;a href=&#34;https://www.anandtech.com/show/15217/intels-manufacturing-roadmap-from-2019-to-2029&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;incremental improvements&lt;/a&gt;, and the end of the
arguably more important &lt;a href=&#34;https://en.wikipedia.org/wiki/Dennard_scaling&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Dennard scaling&lt;/a&gt;, we&amp;rsquo;re entering a new
era where general purpose architectures are no longer the solution.
Reconfigurable architectures are one of the hottest research topics and perhaps
hold the key to application-specific hardware acceleration. However, without
a sane programming model, reconfigurable architectures might not achieve the
success they deserve.&lt;/p&gt;

&lt;h3 id=&#34;reconfigurable-architectures&#34;&gt;Reconfigurable Architectures&lt;/h3&gt;

&lt;p&gt;Since the dawn of computer architecture, we&amp;rsquo;ve focused on building processors
that are good at executing &lt;em&gt;every&lt;/em&gt; conceivable program. The advances in
pipelined designs, speculative and out-of-order execution all try to
dynamically discover regularity and parallelism in arbitrary programs and
execute them as fast as possible. The performance benefits of these technologies
are inarguable. However, all good things come at a price. In their
single-minded zealotry to improve single threaded performance, processors introduce
an incredible amount of &lt;em&gt;control overhead&lt;/em&gt;. Figure 1 shows the energy
breakdown of executing an add instruction. The control dominates the cost of
executing an instruction.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;figure&gt;
&lt;img src=&#34;./img/energy-breakdown.png&#34;
     alt=&#34;Energy breakdown of executing an add instruction on 45nm technology.&#34;&gt;
&lt;/img&gt;
&lt;figcaption&gt;
Fig 1.
Energy breakdown of executing an add instruction from
&amp;ldquo;&lt;a href=&#34;https://ieeexplore.ieee.org/document/6757323&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Computing&amp;rsquo;s Energy Problem&lt;/a&gt;&amp;rdquo; [Horowitz, 2014].
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;So while modern processors
can execute arbitrary programs quickly, they leave a lot of room for improvement
with an individual program.
Instead of paying for the cost of the general control structures in every program,
what if your processor could pay for the exactly the amount of control required
to execute the current program.
What if you
could &lt;em&gt;reconfigure&lt;/em&gt; your architecture
based on the currently executing program?
Reconfigurable architectures refers to the general class of architectures
that allow some degree of application-specific reconfigurability. The term
&amp;ldquo;reconfigurable architectures&amp;rdquo; is incredibly broad and spans everything from
the reconfigurability of meshes in &lt;a href=&#34;http://opencelerity.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;massive many-cores&lt;/a&gt; to bit-level
reconfigurable architectures. In this post, we&amp;rsquo;ll be focusing on Field
Programmable Gate Arrays (FPGAs) as a reconfigurable accelerator.&lt;/p&gt;

&lt;h3 id=&#34;fpgas-as-computational-accelerators&#34;&gt;FPGAs as Computational Accelerators&lt;/h3&gt;

&lt;p&gt;FPGAs were initially developed as high-performance simulators for circuit
designs. Testing a hardware design requires simulating its behavior over
thousands of clock cycles. With larger and more complex, the computational
power required to simulate and track the state of a design becomes increasingly
hard. Unfortunately, simulating a hardware design on a traditional processor
does not scale&amp;mdash;imagine trying to simulate an i3
processor on a Pentium 4. FPGAs were designed as simulation accelerators. They
provide &lt;em&gt;bit-level&lt;/em&gt; reconfigurability which allows them to simulate wires and
gates in a hardware design.&lt;/p&gt;

&lt;p&gt;The bit-level reconfigurability also made FPGAs
viable as a cheaper, low-volume alternate to application specific integrated
circuits (ASICs). Instead of taping-out custom chips, FPGAs could be used to
prototype and integrate such accelerators without paying for a full
silicon tape-out. In domains like
signal processing or networking, where real-time deadlines really matter and
CPUs struggle to meet high-throughput requirements, FPGAs were successfully
used as computational accelerators. The common thread in all of these use cases
is that we really want to design custom circuits but don&amp;rsquo;t want to pay the
costs of producing a whole new chip.&lt;/p&gt;

&lt;p&gt;FPGAs happily chugged along in these niche roles for a long time without taking
off in a big way. Researchers knew that FPGAs could play a big role as flexible
accelerators but didn&amp;rsquo;t have a &amp;ldquo;killer app&amp;rdquo;. Between 2010-2016, an exceptional
team of computer architects demonstrated
that FPGAs could be used as
computational accelerators &lt;em&gt;inside datacenters&lt;/em&gt; through the &lt;a href=&#34;https://www.microsoft.com/en-us/research/project/project-catapult/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Catapult&lt;/a&gt;
project. Catapult, and its successor &lt;a href=&#34;https://www.microsoft.com/en-us/research/project/project-brainwave/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;BrainWave&lt;/a&gt;, showed that not only can
FPGAs significantly improve the performance of modern large-scale applications,
they provide enough flexibility to be used in multiple domains, accelerating
everything from Bing search, Azure cloud network, and most recently, ML models.&lt;/p&gt;

&lt;p&gt;Other cloud services like AWS have jumped on this trend and now offer &lt;a href=&#34;https://aws.amazon.com/education/F1-instances-for-educators/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;F1
instances&lt;/a&gt; which provide access to high-end FPGA units through AWS&amp;rsquo;s
pay-what-you-use model.&lt;/p&gt;

&lt;h3 id=&#34;fpga-programming-101&#34;&gt;FPGA Programming 101&lt;/h3&gt;

&lt;p&gt;Owing to its root as a hardware simulator, FPGA programming toolchains repurpose
existing hardware design languages (HDLs). As a circuit simulator, this is
a really good idea. You can simply take your preexisting hardware design and
run it on an FPGA.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;Unfortunately, when trying to run high-level application code
the level of abstraction afforded by HDLs is far too low-level.
Imagine
trying to write a convolution kernel by specifying every wire connection
into every adder and the computation that occurs at every clock cycle. Proponents
of HDLs will point out that we can eek out every bit of performance from a
low-level hardware design. However, this also means that design iteration times
are much worse. It can take many weeks of engineering effort to implement
and optimize a design.&lt;/p&gt;

&lt;p&gt;I am by no means the first person to point this productivity-performance
trade-off. Practitioners and researchers have created a multitude of
HDLs to improve the level of abstraction: &lt;a href=&#34;https://bluespec.com/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;BlueSpec&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/SystemVerilog&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;SystemVerilog&lt;/a&gt;, &lt;a href=&#34;https://github.com/cornell-brg/pymtl3&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;PyMTL&lt;/a&gt;,
&lt;a href=&#34;https://www.chisel-lang.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Chisel&lt;/a&gt;, etc. all aim to use host languages to improve the level of abstraction
in some manner. For example, Chisel is embedded in Scala and provides
modularity and parameterization mechanisms using Scala&amp;rsquo;s type system.
However, HDLs still &lt;em&gt;fundamentally&lt;/em&gt; operate at the gate-and-wire
level of abstraction. Chisel designs, after being typechecked by the Scala
compiler, are expanded into a structural specification of the hardware design.&lt;/p&gt;

&lt;p&gt;A more radical technique to lift the level of abstraction would be to specify
&lt;em&gt;how&lt;/em&gt; the computation occurs and use a compiler to generate the hardware for
that specification. The architecture community has been exploring the idea
of transforming behavioral (or functional) descriptions of computation
into hardware designs. This is commonly referred to High-Level Synthesis (HLS)
in the community.&lt;/p&gt;

&lt;h3 id=&#34;high-level-synthesis&#34;&gt;High-Level Synthesis&lt;/h3&gt;

&lt;p&gt;High-Level Synthesis&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; is the idea of compiling a computational description
in a high-level programming language&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;, like C or C++, into an HDL like
Verilog. HLS has been quite successful in a multitude of domains&amp;mdash;everything
from &lt;a href=&#34;https://ieeexplore.ieee.org/document/1466178&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;digital signal processing&lt;/a&gt; to &lt;a href=&#34;https://dl.acm.org/doi/10.1145/3020078.3021741&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;machine learning
accelerators&lt;/a&gt; has been implemented in HLS.&lt;/p&gt;

&lt;p&gt;The semantic gap between a functional description and timed hardware structures
is quite large. Hardware designs are &lt;em&gt;timed&lt;/em&gt; because they explicitly describe
the
behavior of individual circuits at the granularity of clock cycles. An HLS
compiler needs to transform the functional description into a &lt;em&gt;data path&lt;/em&gt;,
which describes the hardware structures that perform computations, and
a &lt;em&gt;control path&lt;/em&gt;, which describes the computation performed by components every
cycle.&lt;/p&gt;

&lt;p&gt;The promise of transforming &lt;em&gt;any&lt;/em&gt; C++ program into hardware is absurd at its
face. C++ programs dynamically allocate memory, use complicated control
structures, and are notoriously hard to analyze. Compare this to physical
hardware where memory sizes and control structures need to statically generated
at compile time.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll leave the specifics of where HLS fails for a future blog post. If you&amp;rsquo;re
curious, dive into &lt;a href=&#34;./files/pubs/dahlia.pdf&#34;&gt;our paper&lt;/a&gt; on &lt;a href=&#34;https://capra.cs.cornell.edu/dahlia&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Dahlia&lt;/a&gt; which identifies
some of these problems and shows how little bit of programming languages magic
can help.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re curious about this area, jump onto these cool blog posts and papers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.cornell.edu/~asampson/blog/fpgaabstraction.html&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;FPGAs Have the Wrong Abstraction&lt;/a&gt; by Adrian Sampson.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/5737854?tp=&amp;amp;arnumber=5737854&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;High-Level Synthesis for FPGAs: From Prototyping to Development&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/Cloud-Scale-Acceleration-Architecture.pdf&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;A Cloud-Scale Acceleration Architecture&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(If you&amp;rsquo;ve written a blog post on HLS-related stuff, email it to me so I can
add it here!)&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks for &lt;a href=&#34;http://adriansampson.net&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Adrian Sampson&lt;/a&gt; and &lt;a href=&#34;https://www.cs.cornell.edu/~avh/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Alexa VanHattum&lt;/a&gt; for providing feedback on early
drafts of this blog post&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:2&#34;&gt;I apologize to my architect friends. Running designs on an FPGA in reality can be an incredible challenge. FPGAs have different kinds of memory and performance characteristics. Most hardware design codebases are carefully engineered to separate FPGA-specific design decisions from the core design.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;Architects adopted the &amp;ldquo;Synthesis&amp;rdquo; terminology from hardware design workflows. A hardware design is &lt;em&gt;synthesized&lt;/em&gt; into silicon. Since we&amp;rsquo;re now generating designs from a high-level language, we&amp;rsquo;ll call it &amp;ldquo;High-level Synthesis&amp;rdquo;. From a compiler/programming languages viewpoint, this is just a compiler.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;The choice of C or C++ as a &amp;ldquo;high-level language&amp;rdquo; might seem odd but to architects, who operate at the level clock cycles and hardware structures, C++ is a huge jump in abstraction.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The First Two Years of My PhD</title>
      <link>/post/first-two-years/</link>
      <pubDate>Wed, 08 Apr 2020 00:40:17 -0400</pubDate>
      
      <guid>/post/first-two-years/</guid>
      <description>

&lt;p&gt;With the end of the Spring ’20 semester a month away, I have spent almost
two academic years at Cornell. A quick rundown of everything that happened:&lt;/p&gt;

&lt;h3 id=&#34;failures&#34;&gt;Failures&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Short paper on &lt;a href=&#34;https://github.com/cucapra/futil&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;FuTIL&lt;/a&gt; rejected from LCTES ’20.&lt;/li&gt;
&lt;li&gt;Rejected from Facebook fellowship ’20.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./publication/dahlia&#34;&gt;Dahlia&lt;/a&gt; rejected from ASPLOS ’20 with two weak rejects.&lt;/li&gt;
&lt;li&gt;Rejected from Microsoft research internship for summer ’19.&lt;/li&gt;
&lt;li&gt;Rejected from Qualcomm fellowship application ’19.&lt;/li&gt;
&lt;li&gt;Rejected from the Facebook fellowship ’19.&lt;/li&gt;
&lt;li&gt;Rejected from the Symantec fellowship ’19.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;successes&#34;&gt;Successes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Short paper on &lt;a href=&#34;https://github.com/cucapra/diospyros&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Diospyros&lt;/a&gt; accepted to LCTES ’20.&lt;/li&gt;
&lt;li&gt;Selected as a finalist for the Qualcomm fellowship ’20.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;./publication/dahlia&#34;&gt;Dahlia&lt;/a&gt; accepted to PLDI ’20.&lt;/li&gt;
&lt;li&gt;Research internship at &lt;a href=&#34;https://research.fb.com/category/augmented-reality-virtual-reality/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Facebook Reality Labs&lt;/a&gt; for summer ’19.&lt;/li&gt;
&lt;li&gt;Gave an invited talk to the Princeton Architecture and PL groups.&lt;/li&gt;
&lt;li&gt;Organized the &lt;a href=&#34;https://www.cs.cornell.edu/courses/cs7194/2019sp/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Great works in PL&lt;/a&gt; seminar.&lt;/li&gt;
&lt;li&gt;Organized the programming languages retreat in Fall ’19.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;fall-18&#34;&gt;Fall ’18&lt;/h3&gt;

&lt;p&gt;I started at Cornell and was terrified that I would not be able to find an
advisor. I set up meetings with the PL faculty and Cornell and decided to
do a rotation with &lt;a href=&#34;http://adriansampson.net&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Adrian Sampson&lt;/a&gt; during the fall and switch to
working with &lt;a href=&#34;https://www.cs.cornell.edu/~jnfoster/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Nate Foster&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Adrian pitched me three projects: Use program synthesis
to automatically partition programs for reconfigurable architectures,
build a type system for a high-level programming language
for FPGAs, and a type system for graphics
and shader programming languages.&lt;/p&gt;

&lt;p&gt;I decided to work on the type system for FPGA programming (called Dahlia). I
was unsure that I would be a good fit for this project because I had no
background in computer architecture research. I hoped that my programming
languages experience would be useful for the project and that I could learn
enough about architecture to contribute to the project.&lt;/p&gt;

&lt;p&gt;I started reading about FPGAs, implementing various features for the Dahlia
compiler, and writing down proofs for various type system properties.
I also got involved with the programming languages group and gave my
&lt;a href=&#34;https://www.cs.cornell.edu/courses/cs7190/2018fa/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;first pldg talk&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We designed several language features for Dahlia. A particularly thorny
design issue was supporting complex iteration patterns while providing
type safety. We came up with &lt;a href=&#34;https://capra.cs.cornell.edu/seashell/docs/view.html&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;memory
views&lt;/a&gt; to solve this.
The design of views felt inelegant.&lt;/p&gt;

&lt;p&gt;I volunteered at OOPSLA ’19 in Boston where I met a lot of new and old
friends. I applied to industrial fellowships and was rejected from them.
Adrian said that they prefer to accept more senior students and that applying
was more important than being accepted. I agreed.&lt;/p&gt;

&lt;p&gt;During the semester I also realized that I was enjoying working on
Dahlia and asked Adrian to formally be my advisor. He agreed.&lt;/p&gt;

&lt;h3 id=&#34;winter-18&#34;&gt;Winter ’18&lt;/h3&gt;

&lt;p&gt;I went back to India for the winter break where I read a bunch of papers
and reviewed applications for PhD applicants. I convinced &lt;a href=&#34;https://www.cs.cornell.edu/~jnfoster/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Nate&lt;/a&gt; to
help me organize the &lt;a href=&#34;https://www.cs.cornell.edu/courses/cs7194/2019sp/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Great works in PL&lt;/a&gt; seminar as an excuse to
read classic PL papers.&lt;/p&gt;

&lt;h3 id=&#34;spring-19&#34;&gt;Spring ’19&lt;/h3&gt;

&lt;p&gt;I came back to Cornell and started implementing memory views in Dahlia.
I kept feeling that the OCaml codebase was slowing me down so I &lt;a href=&#34;https://github.com/cucapra/dahlia/pull/46&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;rewrote
Dahlia&lt;/a&gt; in Scala and implemented
memory views. The implementation demonstrated that views were inelegant
so we came up with a new implementation of memory views.&lt;/p&gt;

&lt;p&gt;Implementing views turned out to be a lot more challenging than I originally
expected and it took me four tries to get it right. Before the final attempt,
we realized there was a fundamental problem with checking views that we didn&amp;rsquo;t
know how to solve. I was feeling particularly down that day. During my
walk back home, I discovered an elegant solution for compositionally reasoning
about views.&lt;/p&gt;

&lt;p&gt;The biggest challenge with Dahlia was finding the right pitch for it.
We had some idea that it made hardware designs &amp;ldquo;more predictable&amp;rdquo; because
each language construct had a direct hardware mapping. However, we didn&amp;rsquo;t
know how to demonstrate this &amp;ldquo;predictability&amp;rdquo;. I was wary of qualitative
arguments. I spent the semester writing code and text. We started porting
an FPGA programming benchmark suite to Dahlia to see how it faired with larger
examples.&lt;/p&gt;

&lt;p&gt;In the background, I decided to do a summer internship that year and started
interviewed with MSR and Facebook Reality Labs (FRL). MSR rejected me and I
eventually accepted an offer from the silicon research team at FRL. I
also attended ASPLOS ’19 with Adrian and made a lot
of new architecture friends. Architects seemed to be livelier than PL
people because they&amp;rsquo;re living on the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Explicit_data_graph_execution&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;EDGE&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;summer-19&#34;&gt;Summer ’19&lt;/h3&gt;

&lt;p&gt;I spent my summer in Redmond at FRL using program synthesis to solve hardware
problems. Working on program synthesis is a roller coaster: the
solver gives you solutions and you&amp;rsquo;re happy. At some point it stops scaling
and you don&amp;rsquo;t know what to do anymore and everything is sad.&lt;/p&gt;

&lt;p&gt;I also wrote a few short sections for the Dahlia paper hoping to hit the
ASPLOS ’20 deadline.&lt;/p&gt;

&lt;h3 id=&#34;fall-19&#34;&gt;Fall ’19&lt;/h3&gt;

&lt;p&gt;My team at FRL sufficiently liked my project to ask me to continue working
on an offshoot. I realized that if I worked on a program synthesis project
alone, I would be sad all the time. I asked &lt;a href=&#34;https://www.cs.cornell.edu/~avh/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Alexa VanHattum&lt;/a&gt; if
she wanted to collaborate on it with me and she said yes.&lt;/p&gt;

&lt;p&gt;I flew back to Ithaca a week before the ASPLOS ’20 deadline fully expecting
to miss the deadline since we didn&amp;rsquo;t have a lot of content in the paper.
Adrian said we should hit the deadline so I switched gears into paper
writing mode. We wrote a paper in a week and submitted it to ASPLOS. I didn&amp;rsquo;t
expect the paper to get in because of a weak evaluation.&lt;/p&gt;

&lt;p&gt;A central problem with the evaluation was that it simply reimplemented C++
benchmarks in Dahlia which resulted in the same area and latency numbers
as the baselines. The evaluation didn&amp;rsquo;t say anything interesting about how
Dahlia enabled &amp;ldquo;predictable hardware design&amp;rdquo;&amp;mdash;which was the title of
our paper. I was starting to feel angsty about the project and felt like there
was no way evaluate it.&lt;/p&gt;

&lt;p&gt;I was burned out from the paper writing so I asked my friend &lt;a href=&#34;https://samginzburg.com/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Sam
Ginzburg&lt;/a&gt; to host me at Princeton for a week. He recommended that I
give a talk to the architecture group which was a great idea but destroyed
my plans of not working during the Princeton visit. I visited Princeton, gave
a talk, and met a lot of cool people. Sam was working on a measurement project
and had a lot of pretty graphs. I decided that the only way to calm my angst
with Dahlia was to perform measurements and quantify predictability. I did
not yet know how.&lt;/p&gt;

&lt;p&gt;I continued spending my time implementing the compiler and getting the
benchmarks running. During an auspicious trip to the Applications Driving
Architecture (ADA) symposium, I came up with a plan to show that Dahlia enabled
predictable design.&lt;/p&gt;

&lt;p&gt;The plan was as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Take a hardware design and enumerate all the design points.&lt;/li&gt;
&lt;li&gt;Run all the points and extract statistics (area and latency).&lt;/li&gt;
&lt;li&gt;Show that the subset of design points Dahlia accepts smoothly trade off
area for latency and are therefore &amp;ldquo;predictable&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Profit.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The challenging part of this plan was getting all the data. A back-of-the-envelope
calculation showed that we&amp;rsquo;d need a few months of compute time to
get all the data. I had, unfortunately, reached a point where I needed to
build a distributed experimentation framework.&lt;/p&gt;

&lt;p&gt;I got to work building the framework on top of an existing in-house benchmarking
server. It took me three weeks of relentless Python hacking to get multiple
AWS machines to run FPGA designs. Once we had that, pretty graphs started
rolling out and I started confirming various claims about Dahlia quantitatively.
Around this time, Dahlia was rejected from ASPLOS.&lt;/p&gt;

&lt;p&gt;While this was expected, I was still sad for a few days. We decided to resubmit
to PLDI. With three weeks to go, I ran the capstone
experiment: enumerate 32,000 points and run them on the 80 workers. I
calculated that it would take 5 days to finish the jobs. I ran into numerous
issues like &lt;code&gt;ls&lt;/code&gt; being too slow, job uploads taking three days, and monitoring
scripts DDoS-ing the servers. I babysat the servers, painfully restarting
dead workers and failed jobs, and eventually got the
results. The graphs looked pretty and validated Dahlia&amp;rsquo;s claims. I was very
tired but happy.&lt;/p&gt;

&lt;p&gt;During the last week while writing and finishing up the final experiments, I
started staying late in the office. Three days before the deadline (Nov 19),
I finished all the experiments and got cookies at midnight to celebrate this.
After the cookies, I decided to bike back to home. I
started biking down 2am. At 2.05am, I fell from my bike during a sharp turn
and broke my left wrist. My roommate took me the ER where I got a splint. I was heartbroken.&lt;/p&gt;

&lt;p&gt;I woke up the next day and went into the lab after getting a proper arm cast.
I could no longer type on a keyboard so I started handwriting the edits to
the paper which my co-authors then put into the paper. At 1am on November 23,
we &lt;a href=&#34;https://twitter.com/notypes/status/1198111419704717312&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;submitted&lt;/a&gt; the
Dahlia paper to PLDI ’20. I was unsure if the paper would get in but I was
proud of the work we had done.&lt;/p&gt;

&lt;p&gt;The semester rolled on and I started brainstorming ideas with Alexa and FRL
on a new project. We decided to use program synthesis to generate
high-performance kernels for DSPs.&lt;/p&gt;

&lt;h3 id=&#34;winter-19&#34;&gt;Winter ’19&lt;/h3&gt;

&lt;p&gt;I went back home to India to recuperate from the broken arm. I proposed
submitting a Qualcomm fellowship proposal for our DSP project. We quickly
hacked up a demo project (called &lt;a href=&#34;https://github.com/cucapra/diospyros&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Diospyros&lt;/a&gt;) and submitted the proposal.&lt;/p&gt;

&lt;h3 id=&#34;spring-20&#34;&gt;Spring ’20&lt;/h3&gt;

&lt;p&gt;I came back to Cornell in the spring. Doctor told me that while my broken wrist
bone had healed, a cartilage tear in my wrist might never properly heal. I
wondered if a paper submission was worth a lifelong injury (it wasn&amp;rsquo;t).&lt;/p&gt;

&lt;p&gt;The semester rolled on and we were accepted for stage 2 of the Qualcomm
proposal. We continued hacking on the project and wrote an even stronger stage 2
proposal with real graphs. Emboldened by the success, we also decided to write
a work-in-progress paper for LCTES ’20. In parallel, I joined another project
to build an intermediate language (called &lt;a href=&#34;https://github.com/cucapra/futil&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;FuTIL&lt;/a&gt;) for compiling high-level
languages to hardware circuits. I convinced my collaborators for that project
to submit an LCTES paper as well. We wrote two very good papers and submitted
them.&lt;/p&gt;

&lt;p&gt;In the meantime PLDI reviews came back and they were incredibly positive:
two strong accepts and two weak
accepts. Adrian said it was almost certainly enough to get into PLDI. We
wrote up a rebuttal and submitted it. Two weeks later, Dahlia was accepted
to PLDI ’20. Another week after the acceptance I submitted an artifact to
the PLDI artifact evaluation committee. I also volunteered for the committee
and reviewed some cool artifacts in the following weeks.&lt;/p&gt;

&lt;p&gt;I was generally happier about things, especially since I had published my first
grad school paper. However, at the start of March, everything turned upside
down. Due to the COVID-19 crisis, Cornell shut down its campus and PLDI
transformed into a virtual conference. I felt sad that I wouldn&amp;rsquo;t be able
to give a talk on Dahlia in paper. Sad enough to write a &lt;a href=&#34;./post/virtual-cs-conferences/&#34;&gt;blog
post&lt;/a&gt; about it.&lt;/p&gt;

&lt;p&gt;A few weeks into working from home and adjusting to our new reality, we heard
back from LCTES. The paper on Diospyros is accepted while the one on FuTIL is
rejected. We also hear back from Qualcomm saying that we made it to the final
stage.&lt;/p&gt;

&lt;h3 id=&#34;epilogue&#34;&gt;Epilogue&lt;/h3&gt;

&lt;p&gt;My first two years in grad school were a lot of expected and unexpected things.
The ups and downs of research were expected. The ups and downs of life were
not (injuries and global pandemics). This post leaves out a lot of my personal
accomplishments: I made a lot of friends, I took up biking and baking, I got
healthier, etc. Submitting my first paper was a big accomplishment for me but
I don&amp;rsquo;t I like the way I got to it. I sacrificed my personal health (due to
my own work ethic) and injured myself. Going forward, I want to set better
boundaries and think harder about the trade-offs between my life and my
research. I am grateful to the many people who made my first two years at
Cornell bearable.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/lctes-dios/</link>
      <pubDate>Tue, 07 Apr 2020 23:33:59 -0400</pubDate>
      
      <guid>/news/lctes-dios/</guid>
      <description>&lt;p&gt;Work-in-progress paper on &lt;a href=&#34;https://github.com/cucapra/diospyros&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Diospyros&lt;/a&gt; accepted to &lt;a href=&#34;https://conf.researchr.org/series/LCTES&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;LCTES&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/qualcomm-finalist/</link>
      <pubDate>Tue, 07 Apr 2020 23:30:26 -0400</pubDate>
      
      <guid>/news/qualcomm-finalist/</guid>
      <description>&lt;p&gt;Finalist for the &lt;a href=&#34;https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/2020-north-america&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Qualcomm Fellowship&lt;/a&gt; with &lt;a href=&#34;https://www.cs.cornell.edu/~avh/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Alexa VanHattum&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Cost of Virtualizing CS Conferences</title>
      <link>/post/virtual-cs-conferences/</link>
      <pubDate>Wed, 18 Mar 2020 23:15:05 -0400</pubDate>
      
      <guid>/post/virtual-cs-conferences/</guid>
      <description>

&lt;p&gt;Conferences in computer science are an odd occurrence. Unlike most other
research fields which primarily focus on publishing in journals, conferences
ended up being the primary publication and presentation venue in CS. They also
became the place where researchers network with each other,
learn about ongoing research, and drink beer with their grad school buddies.&lt;/p&gt;

&lt;p&gt;Because of this, conference presentations and networking play an incredibly
important part of a junior researcher&amp;rsquo;s career. Conferences allow us to show
our research to our community and have other people learn about us. In my field
of research, programming languages and systems, it takes anywhere between one
year to multiple years to complete a project. Add to that yearly deadlines and
specialized venues which results in a junior PhD student having anywhere from
two to four presentations before they go on the job market. Our recognition in
our community from our presentations and our papers is what gets us invitation
for interviews and job offers.&lt;/p&gt;

&lt;p&gt;Unfortunately, with the outbreak of &lt;a href=&#34;https://en.wikipedia.org/wiki/Coronavirus_disease_2019&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;COVID-19&lt;/a&gt;, our world has been turned
upside down. Beyond the incredible amounts of fear, uncertainty, and human
suffering it has caused, it has also destroyed one of the core mechanisms of
conducting science&amp;mdash;meeting people. Multiple major academic conferences
(&lt;a href=&#34;https://asplos-conference.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ASPLOS&lt;/a&gt;, &lt;a href=&#34;https://iclr.cc/Conferences/2020/virtual&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ICLR&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/PLDI/status/1240401711124090883&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;PLDI&lt;/a&gt;) have been canceled. Junior researchers, who had
decided to go on job markets, find internships, or visit another institutions
have had to cancel all of their plans. The impact of these things is
unquantifiable&amp;mdash;how does one measure the effect of a missed serendipitous
research collaboration, or that one person on a hiring committee hearing about
your work?&lt;/p&gt;

&lt;p&gt;However, I am not here to complain about missed conferences. Canceling
conferences in the midst of a global pandemic is &lt;em&gt;the right thing&lt;/em&gt; to do.
I instead want to figure out how we as a community can recreate the
opportunities that conferences create for us every year. I am not an expert in
this so I will need help. I have attempted to summarize the crucial
opportunities conferences give us, what the challenges of running a virtual
conferences are, and what options we have given that physical meetings are out
of the question for a while.&lt;/p&gt;

&lt;h3 id=&#34;goals-of-a-conference&#34;&gt;Goals of a conference&lt;/h3&gt;

&lt;p&gt;From my (second-year PhD student in a relatively small community) perspective,
conferences traditionally satisfy the following goals:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Dissemination of research&lt;/strong&gt;: The primary goal of any conference is to allow
researchers to present their work to their peers and discuss it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Welcoming new researchers&lt;/strong&gt;: The bloodline of our communities are new
researchers. From undergrads who are attending conferences for the first
time to PhD student presenting their research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The &amp;ldquo;Hallway&amp;rdquo; track&lt;/strong&gt;: Well understood to be the actual primary goal of
any conference, the hallway track is the colloquial name for researchers
hanging out with each other and discussing research and whatever else that
comes to their mind. It allows us to build long term connections within our
community.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;options-for-virtual-conferences&#34;&gt;Options for Virtual conferences&lt;/h3&gt;

&lt;p&gt;Given that most health organizations have recommended that non-essential
travel be suspended, our only choice is to have virtual conferences in some
format. Virtual formats present several challenges:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Multiple time-zones&lt;/strong&gt;: Since researchers are not directly traveling to
one physical location for the conference, it&amp;rsquo;s safe to assume they will
distributed across the world in different time-zones.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lack of commitment&lt;/strong&gt;: As a friend of mine put it, it&amp;rsquo;s hard to set aside
the time to interact with presenters (who are possibly remote) when there
are other commitments like teaching a class or having research meetings.
Physical conferences act as a forcing function to set this time aside.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Both of these problems are challenging to solve. Following are some proposals
I&amp;rsquo;ve seen discussed/implemented at currently canceled conferences.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Recorded presentations&lt;/strong&gt;: The bare minimum any conference can do to
satisfy the first goal is to have authors record research talks and upload
them to YouTube. This will allow researchers to reach out to the people who
are most interested in their work and already know about it, but not a wider
audience that a physical conference gives access to. It might also be
possible to welcome new researchers through videos but they&amp;rsquo;d likely feel
impersonal.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Chatrooms for discussing papers&lt;/strong&gt;: In addition to uploading all the talks
to YouTube, &lt;a href=&#34;https://asplos-conference.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ASPLOS 20&lt;/a&gt; created a Slack channel to discuss
each paper and co-located workshops. This improves the possibility of direct
interactions by making community members available in the same place.
Unfortunately, there really is no way of creating the hallway track in such
a setup. As a junior student, it might be hard or impossible to get
introductions to/talk to other researchers when they are not present in
person. Furthermore, because of the asynchronous nature of chatrooms, it
might be hard to have detailed conversations with people in different
timezones.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Livestreaming the conference&lt;/strong&gt;: Livestreaming the conference in real time
brings the experience as close to a conference session as possible. People
are required to commit time beforehand and ask questions to right after
a talk. Setting this up is non-trivial owing to time zone issues. Again,
while this provides the opportunity for more direct conversations, there
doesn&amp;rsquo;t seem to be a good way to recreate a hallway track.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Postpone the conference/Merge it with another&lt;/strong&gt;: The nuclear option of
pushing back the conference and waiting out the pandemic. By definition,
this will recreate the experience of a conference. However, this would be
incredibly hard to do since conferences are carefully planned to not overlap
with other conferences in relevant areas. A different approach might to be
have a bigger conference the next year and have papers from both &lt;em&gt;this year&lt;/em&gt;
and &lt;em&gt;next year&lt;/em&gt; be presented there. Again, I imagine this would be a
nightmare to organize. It also fundamentally cannot recreate opportunities
for researchers who go on the job market this year.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;None of the solutions here are perfect and I wouldn&amp;rsquo;t know which one to choose.
Each of these require hard trade-offs that we, as a community, have to make.
The lack of conferences and the opportunities they create is not measurable
which makes it easier to ignore their impact. I really hope that we can
come up with a solution that is cognizant of this and takes into consideration
the people most impacted by this.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A personal note&lt;/strong&gt;: I had &lt;a href=&#34;https://capra.cs.cornell.edu/dahlia&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;a paper&lt;/a&gt; accepted at PLDI 20. This
is my first first-author paper and I have been incredibly excited to present
this work for a really long time. I always imagined my first presentation
to an exciting and terrifying rite of passage that I would celebrate with
my friends, colleagues, and advisors. I feel a deep sense of loss, almost
as if all the hard work was &amp;ldquo;zeroed out&amp;rdquo; because I can&amp;rsquo;t present it anymore.
I assume other people in my situation feel similarly. I don&amp;rsquo;t know if senior
researchers put this much value in conference presentations (since they&amp;rsquo;ve
already given so many) but it seems important to acknowledge this feeling that
junior researchers have when we come up with solutions for virtual conferences.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/dahlia-pldi2020/</link>
      <pubDate>Sun, 01 Mar 2020 14:29:17 -0500</pubDate>
      
      <guid>/news/dahlia-pldi2020/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://capra.cs.cornell.edu/dahlia&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Dahlia&lt;/a&gt; was accepted to &lt;a href=&#34;http://conf.researchr.org/home/pldi-2020&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;PLDI 2020&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predictable Accelerator Design</title>
      <link>/publication/dahlia/</link>
      <pubDate>Mon, 03 Feb 2020 16:44:36 -0400</pubDate>
      
      <guid>/publication/dahlia/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/news/aec-pldi2020/</link>
      <pubDate>Sat, 01 Feb 2020 15:01:20 -0500</pubDate>
      
      <guid>/news/aec-pldi2020/</guid>
      <description>&lt;p&gt;Member of the PLDI 2020 &lt;a href=&#34;https://pldi20.sigplan.org/track/pldi-2020-PLDI-Research-Artifacts&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Artifact Evaluation Committee&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/dahlia-princeton/</link>
      <pubDate>Sun, 01 Sep 2019 15:02:33 -0500</pubDate>
      
      <guid>/news/dahlia-princeton/</guid>
      <description>&lt;p&gt;Gave an invited talk on Dahlia at Princeton.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/frl2019/</link>
      <pubDate>Wed, 01 May 2019 15:03:23 -0500</pubDate>
      
      <guid>/news/frl2019/</guid>
      <description>&lt;p&gt;Research intern at &lt;a href=&#34;https://www.facebook.com/careers/areas-of-work/facebookrealitylabs/?teams[0]=Facebook%20Reality%20Labs&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Facebook Reality Labs&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Project Management for PhD Students</title>
      <link>/post/project-management/</link>
      <pubDate>Sun, 03 Mar 2019 22:10:39 -0500</pubDate>
      
      <guid>/post/project-management/</guid>
      <description>

&lt;p&gt;Collaborations in systems research is how I&amp;rsquo;ve built some of the best tools
in my research. A larger teams means an expanded vision and being able to pursue more
ambitious ideas but it also incurs an overhead &amp;ndash; team management. Effectively
managing a team and keeping all team members up to date can be stressful and a
daunting task. I think one way to approaching management tasks is by asking
a few concrete questions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What&amp;rsquo;s the primary channel of communication?&lt;/li&gt;
&lt;li&gt;How often should we be meeting? What are the preparing expectations for a meeting?&lt;/li&gt;
&lt;li&gt;How are we managing our code base? What are the expectations about code knowledge?&lt;/li&gt;
&lt;li&gt;How are we managing our TODO items?&lt;/li&gt;
&lt;li&gt;How should we resolve conflicts?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The answers to these questions should evolve with a project. For example, a
project in its prototyping stage might have no restrictions on how or where the
code is kept but a more mature project associated with other projects or
deployments requires careful releases.&lt;/p&gt;

&lt;p&gt;The following sections answer these questions from my experience with teams.
The answers apply for a reasonably mature project with most core infrastructure
decisions already made (which language to use, which toolchains, etc.)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Since I&amp;rsquo;m not the most experienced developer in the world, I would appreciate any suggestions (find my contact information at the end of the post).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;primary-communication&#34;&gt;Primary Communication&lt;/h3&gt;

&lt;p&gt;This is an easy one. Teams can either use email threads or one of the dozens
of chat applications to have conversations about the project.&lt;/p&gt;

&lt;p&gt;The benefit of using a emails is that the team can keep track of individual
threads of conversations easily. However, with multiple projects, this might
get unwieldy.&lt;/p&gt;

&lt;p&gt;Chat apps, on the other hand, make it really quick and easy to communicate with
the team but are usually bad at maintaining separate threads of conversations
cleanly.&lt;/p&gt;

&lt;p&gt;The choice of the primary communication is often already constrained by group
preferences so this is usually a straightforward decision.&lt;/p&gt;

&lt;p&gt;As a side note, team members should try to have long conversations in person.
Text based mediums make it really hard to accurately convey emotions and it
is easy to misread an offhand comment as being aggressive (I&amp;rsquo;ve certainly been
guilty of this!)&lt;/p&gt;

&lt;h3 id=&#34;meetings&#34;&gt;Meetings&lt;/h3&gt;

&lt;p&gt;Meetings act as a synchronization point for the entire team and require some amount
of preparation. I suggest having at least two team meetings every week, one
with your advisor (main meeting) and one without them (student meeting).&lt;/p&gt;

&lt;h4 id=&#34;main-meeting&#34;&gt;Main meeting&lt;/h4&gt;

&lt;p&gt;For the main meeting, every student should be prepared with the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A short weekly update.&lt;/li&gt;
&lt;li&gt;Technical challenges faced during the assigned task.&lt;/li&gt;
&lt;li&gt;Questions or gotchas found during the assigned the task.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the end of the main meeting, each student should leave with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;At least one assigned task for the week. This can be a paper to read and explain, feature to implement, or a theorem to prove.&lt;/li&gt;
&lt;li&gt;A good sense of where to look for answers to their questions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A lot of students (myself included) struggle with prioritizing tasks. Students
involved in research have tons of unstructured time which is not utilized
effectively without a good plan. Assigned tasks help me focus on a task that
I need to get done every week.&lt;/p&gt;

&lt;p&gt;Concretely, I try every week to either complete the tasks assigned to me or
have technical questions that are blocking me ready for the meeting.&lt;/p&gt;

&lt;h4 id=&#34;student-meeting&#34;&gt;Student meeting&lt;/h4&gt;

&lt;p&gt;The student meetings are more informal and are meant for in depth discussions
about small issues that team members are facing in completing their tasks.&lt;/p&gt;

&lt;h3 id=&#34;codebases&#34;&gt;Codebases&lt;/h3&gt;

&lt;p&gt;If you&amp;rsquo;re working on an applied systems project chances are you are building
a software artifact. Regardless of how many people are writing code, it is useful to
check in the code into &lt;a href=&#34;https://en.wikipedia.org/wiki/Version_control&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;source
control&lt;/a&gt;. This makes the code
publicly viewable and commentable by the team members.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The high-level principle behind these guidelines is to minimize the number of locations where critical information such as feature discussions are kept.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Since I primarily use &lt;a href=&#34;https://git-scm.com/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;git&lt;/a&gt; and &lt;a href=&#34;https://github.com/rachitnigam&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Github&lt;/a&gt;, the following guidelines assume your
project is Github-based. When working on a artifact, I have the following
expectations with team members:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The project leaders (graduate students or senior undergrads) should have a
good sense of what is going on with every aspect of the codebase. This means
having a high-level understanding of all pull requests and issue discussions.&lt;/li&gt;
&lt;li&gt;Use &lt;a href=&#34;https://help.github.com/en/articles/about-pull-requests&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;pull requests&lt;/a&gt;
and &lt;a href=&#34;https://help.github.com/en/articles/about-branches&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;branches&lt;/a&gt;. Working
on big features on a separate branch allows other people to work in parallel
while leaving the code in a buildable state. Pull requests are a great way
to get the team&amp;rsquo;s attention on a big change and center discussions around it.&lt;/li&gt;
&lt;li&gt;Keep the git history clean by using &lt;code&gt;git pull -r&lt;/code&gt; and
&lt;a href=&#34;https://help.github.com/en/articles/about-git-rebase&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;rebasing&lt;/a&gt; instead of
merging.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;todo-list&#34;&gt;TODO List&lt;/h3&gt;

&lt;p&gt;Since most of my projects revolve around a software artifact, most of which
are on &lt;a href=&#34;https://github.com/rachitnigam&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Github&lt;/a&gt;, I use Github issues as
a tracking list. Other people I have worked with also use &lt;a href=&#34;https://trello.com/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Trello&lt;/a&gt; or one of the dozens of TODO apps.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The todo list should make it easy to create tasks and have discussions around them and also allow team members to see who is working on what.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;During the development phase of the project, I ask the team to use
issues liberally. The term &amp;ldquo;global tracker&amp;rdquo; refers to the high level view of
all todo items. On Github, this is simply the issues page.&lt;/p&gt;

&lt;p&gt;Largely, I divide issues into three categories:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Trackers&lt;/strong&gt;. Trackers are a collection of smaller issues that logically belong
together but might pollute the global tracker. Use these for reading lists,
benchmark status, and low priority tasks. &lt;a href=&#34;https://github.com/cucapra/seashell/issues?utf8=%E2%9C%93&amp;amp;q=is%3Aissue+label%3ATracker+&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Example&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Proposal&lt;/strong&gt;. Proposal are the heart of the global tracker. Use proposals to
discuss system features, implementation sketches, or big bugs.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Miscellaneous&lt;/strong&gt;: These include questions or small bugs. These should be
high frequency, i.e. created liberally, and answered quickly.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;conflict-resolution&#34;&gt;Conflict resolution&lt;/h3&gt;

&lt;p&gt;This is an often overlooked dimension of team dynamics. Research projects can
often be stressful, especially since students tend to be ambitious and prone
to overworking. Since this process so highly dependent on the team members
and project leads, my guideline can only be personalized for me.&lt;/p&gt;

&lt;p&gt;If a team member feels under too much pressure to do something or dislikes
someone&amp;rsquo;s personal behavior, they can either directly contact the person or
ask one of the team leads to mediate. While daunting, it is much better in the
long run to have frank discussions about team expectations and stresses instead
of letting things get worse.&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;While there are several industrial strength methodologies for team managements,
I like having a much more lightweight team management style. A lot of research
is about exploring new ideas and pursuing crazy ideas. Regardless of which
guidelines you choose to follow, they should not take away the joy of programming
or research!&lt;/p&gt;

&lt;p&gt;Discussion on &lt;a href=&#34;https://news.ycombinator.com/item?id=19321034&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;HackerNews&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/news/aec-pldi2019/</link>
      <pubDate>Fri, 01 Mar 2019 15:03:59 -0500</pubDate>
      
      <guid>/news/aec-pldi2019/</guid>
      <description>&lt;p&gt;Member of the PLDI 2019 &lt;a href=&#34;https://pldi19.sigplan.org/committee/pldi-2019-pldi-research-artifacts-artifact-evaluation-committee&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Artifact Evaluation Committee&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learning to Fail</title>
      <link>/post/learn-to-fail/</link>
      <pubDate>Wed, 19 Dec 2018 07:20:00 +0530</pubDate>
      
      <guid>/post/learn-to-fail/</guid>
      <description>

&lt;p&gt;I often describe the basic philosophy of research using a metaphor: bash your
head in a wall over and over till you find a way to
break it and then repeat it ad nauseam. Sometimes you&amp;rsquo;ll know where the
cracks in the wall are, and sometime you&amp;rsquo;ll know what angle you need to hit the
wall with your head, but fundamentally, you&amp;rsquo;re hitting your head into a wall.&lt;/p&gt;

&lt;p&gt;This is perhaps an unnecessarily graphic description of what research is
like but the point I&amp;rsquo;m trying to get across is that &lt;em&gt;research is hard&lt;/em&gt; and
that &lt;em&gt;failure is the expected outcome&lt;/em&gt;. The primary skill of researcher is
not their ability to come up with good ideas or write code but to persevere
in the face of continuous failure.&lt;/p&gt;

&lt;p&gt;My undergraduate research experience is the primary reason that I skill. I
started research early but I failed. In fact, I failed almost every single
project I worked on. But this failure also removed any illusions of what
research is like and helped me redefine what &amp;ldquo;success&amp;rdquo; should mean.&lt;/p&gt;

&lt;p&gt;Here is a quick summary of my research experience as an undergrad:&lt;/p&gt;

&lt;h3 id=&#34;spring-2016&#34;&gt;Spring 2016&lt;/h3&gt;

&lt;p&gt;I reached out a my undergraduate advisor in my first semester after being
fascinated with Scheme&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. After some back and forth, I quickly started
a project. The project was to build a formal semantics for bash scripts. The
bash specification is large and complicated with a lot of subtle interactions.
The particular phase we were interested in formalizing were the bash shell
&lt;a href=&#34;https://www.gnu.org/software/bash/manual/html_node/Shell-Expansions.html&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;expansions&lt;/a&gt;. We tried to build a Hoare logic style semantics for the expansion, because
we wanted to ultimately verify properties of these shell scripts. Unfortunately,
I showed that such a semantics becomes super complicated and we abandoned the
project&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. A few weeks into research and I had already failed a project.&lt;/p&gt;

&lt;h3 id=&#34;summer-2016&#34;&gt;Summer 2016&lt;/h3&gt;

&lt;p&gt;I came back for the summer and started working on a new, and slightly related
project. The idea was to extend previous work on &lt;a href=&#34;https://dl.acm.org/doi/10.1145/2908080.2908083&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;verifying Puppet
manifests&lt;/a&gt; to
capture the semantics of snippets of shell programs people write into their
Puppet manifests. The previous work had modeled Puppet programs using a
small core calculus based on a Kleene Algebra with Tests (&lt;a href=&#34;https://www.cs.cornell.edu/~kozen/Papers/kat.pdf&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;KAT&lt;/a&gt;) and we wanted to create an active learning
mechanism to learn the underlying automaton by running the shell script in
a docker container.&lt;/p&gt;

&lt;p&gt;Unfortunately, I didn&amp;rsquo;t have a lot of background in either automata theory or
the low level details of system call tracing (which was the core mechanism to
figure out what system calls were being used). I spent half of the summer
jumping back and forth between learning about automata theory and systems and
implementing papers without much to show for it. While I didn&amp;rsquo;t know this
at the time, this project also fizzled out around this time.&lt;/p&gt;

&lt;p&gt;The reason the project fizzled out was because I joined another student&amp;rsquo;s
project where we were trying to automatically synthesize updates for Puppet
manifests by capturing system calls. I worked on this project for the rest
of the summer.&lt;/p&gt;

&lt;h3 id=&#34;fall-2016&#34;&gt;Fall 2016&lt;/h3&gt;

&lt;p&gt;As the summer ended, my advisor proposed joining Fission, another project that
I had been interested in from the start of my summer. This project aimed to
build a single-tiered, secure programming model for writing web applications.
People on the project had built a frontend that could take JavaScript code and
compile it into something that could enforces security conditions.
Around the same time, the Puppet synthesis project slowed down because the
first author was applying to graduate schools and I was focusing more on
Fission. Eventually, I stopped working on Puppet synthesis entirely and even
though it was eventually published&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;To cap off the depressing string of half completed projects, it was around this
time I actually had minor clinical depression and my productivity collapsed. After
attending &lt;a href=&#34;https://conf.researchr.org/home/icfp-2016&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;ICFP &amp;lsquo;16&lt;/a&gt; I decided to
start therapy to &amp;ldquo;fix&amp;rdquo; my clinical depression&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Meanwhile, we also published a &lt;a href=&#34;http://drops.dagstuhl.de/opus/volltexte/2017/7124/pdf/LIPIcs-SNAPL-2017-5.pdf&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;workshop
paper&lt;/a&gt;
on Fission. Unfortunately, after several rewrites of the compiler, people
leaving the project, and fundamental performance issues, it was becoming
painfully clear that Fission would not pan out.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re keeping track, it&amp;rsquo;s &lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; for failed projects.&lt;/p&gt;

&lt;h3 id=&#34;spring-2017&#34;&gt;Spring 2017&lt;/h3&gt;

&lt;p&gt;While making slow progress on Fission, my advisor asked a new question, &amp;ldquo;What
would it take to build a client-side IDE?&amp;ldquo;. In order to build this IDE, we
started investigating different compiler frameworks for JavaScript. We built
multiple passes to simplify JavaScript constructs and around the same time, another
graduate student joined the project. This spring was perhaps the most productive
semester of my undergraduate research career. I had gained enough technical
and programming chops to push on the project without hands-on support. By the
end of this semester, we had managed to build an IDE and give a talk about it
at &lt;a href=&#34;https://nepls.org/Events/31/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;NEPLS &amp;lsquo;17&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;summer-2017&#34;&gt;Summer 2017&lt;/h3&gt;

&lt;p&gt;My advisor was going to be away for most the summer and he recommended that
I do an &amp;ldquo;academic internship&amp;rdquo;. I emailed a professor at Brown University who
took me in for the summer. After a meeting with him during spring break, I
convinced him to let me continue working on my spring research by promising
to integrate my work into the &lt;a href=&#34;https://www.pyret.org/&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Pyret&lt;/a&gt; programming
language.&lt;/p&gt;

&lt;p&gt;I spend a summer trying to improve the performance of our implementation
which didn&amp;rsquo;t work out. However, my collaborator back at UMass had figured
out a solution so continued pushing on.&lt;/p&gt;

&lt;p&gt;Towards the end of the summer, I started looking into integrating our work with
Pyret. The codebase of a production-ready compiler like Pyret that supports
thousands of users every day was daunting and hard to understand by myself.
I spent about two weeks trying to understand it, and frustrated at my lack of
progress, also wrote a &lt;a href=&#34;https://github.com/rachitnigam/pyret-lang.vim&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Vim plugin&lt;/a&gt; for Pyret. Once I understood the code base, it took me two days to
implement the first part of the integration.&lt;/p&gt;

&lt;h3 id=&#34;fall-2017&#34;&gt;Fall 2017&lt;/h3&gt;

&lt;p&gt;Summer came to an end and my most stressful semester in undergraduate began.
I was graduating in three years so I was taking 6 classes, applying
to 10 graduate schools, applying for summer internships, and writing a paper
for our research. It was a lot of work but I did it all. We submitted a
polished paper to PLDI 2018 (which was later &lt;a href=&#34;./publication/stopify&#34;&gt;accepted&lt;/a&gt;).
I was accepted to 8 graduate schools and a software engineering internship
at Google. I eventually decided to start my PhD at Cornell.&lt;/p&gt;

&lt;h3 id=&#34;epilogue&#34;&gt;Epilogue&lt;/h3&gt;

&lt;p&gt;Having spent a few years at Cornell, I have come to appreciate a lot of things
about my undergraduate experience:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;While I failed for more than a year, I learned &lt;em&gt;a lot&lt;/em&gt;. The
amount of implementation work I did made me good at rapid prototyping and
I came with a breadth of knowledge in configuration and web languages,
secure systems, and formal language theory.&lt;/li&gt;
&lt;li&gt;The infectious optimism of my advisor kept me going through all the failures.
The most important piece of advice he gave me was: &amp;ldquo;You&amp;rsquo;ll figure it out!&amp;rdquo;&lt;/li&gt;
&lt;li&gt;I learned that I work best when I collaborate with people. It is easier
to be excited about research when someone else is also excited about it
with you.&lt;/li&gt;
&lt;li&gt;It is really hard to execute research ideas. A lot of people can come up
with really good ideas but it takes a lot of work and dedication to
push through a project. I&amp;rsquo;ve come to respect the latter way more than the
former.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I feel privileged in having a undergraduate research career where I was
given the opportunity to fail. When I started my PhD, I had no illusions
about what research was: it requires a religious amount of faith and hard work
before you can see any progress.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Have comments? &lt;a href=&#34;mailto:rachit.nigam12@gmail.com&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;Email&lt;/a&gt; or &lt;a href=&#34;https://twitter.com/notypes&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;tweet&lt;/a&gt; at me.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;Yes, I am a walking PL cliché.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Michael Greenberg, one of our collaborators, continued working on this and has come up with some &lt;a href=&#34;http://www.cs.pomona.edu/~michael/papers/px2018.pdf&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;nice results&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;This eventually became a &lt;a href=&#34;https://aaronweiss.us/pubs/ase17.pdf&#34; rel=&#34;noreferrer&#34; target=&#34;_blank&#34;&gt;paper&lt;/a&gt;.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;Researchers are people who sometimes work extraordinarily hard at the expense of their own health. It is important to realize that your work is significantly less important that your health.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;↩&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
