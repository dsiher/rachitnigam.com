<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.49.2" />
  

  
  
  
  
    
      
    
  
  <meta name="description" content="THIS IS A DRAFT POST. DO NOT DISTRIBUTE.
 This is quick overview of my research on Dahlia, a new programming language that leverages sub-structural types to make hardware design predictable.
 This blog post assumes some familiarity with reconfigurable architectures and High-Level Synthesis. If you want a quick overview on those, check out my blog post on compiling for the reconfigurable future.
High-Level Synthesis (HLS) is the idea of transforming functional descriptions of programs into performant and efficient hardware designs.">

  
  <link rel="alternate" hreflang="en-us" href="../../post/predictable-accelerator-design/">

  


  

  
  
  <meta name="theme-color" content="#000">
  

  <link rel="stylesheet" href="../../css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="../../styles.css">
  
  <link rel="stylesheet" href="../../css/syntax.css">
  

  
  <link rel="alternate" href="../../index.xml" type="application/rss+xml" title="Rachit Nigam">
  <link rel="feed" href="../../index.xml" type="application/rss+xml" title="Rachit Nigam">
  

  <link rel="manifest" href="../../site.webmanifest">
  <link rel="icon" type="image/png" href="../../img/dusk-asterisk.png">
  

  <link rel="canonical" href="https://rachitnigam.com">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@notypes">
  <meta property="twitter:creator" content="@notypes">
  
  <meta property="og:site_name" content="Rachit Nigam">
  <meta property="og:url" content="/post/predictable-accelerator-design/">
  <meta property="og:title" content="FPGA programming for the rest of us | Rachit Nigam">
  <meta property="og:description" content="THIS IS A DRAFT POST. DO NOT DISTRIBUTE.
 This is quick overview of my research on Dahlia, a new programming language that leverages sub-structural types to make hardware design predictable.
 This blog post assumes some familiarity with reconfigurable architectures and High-Level Synthesis. If you want a quick overview on those, check out my blog post on compiling for the reconfigurable future.
High-Level Synthesis (HLS) is the idea of transforming functional descriptions of programs into performant and efficient hardware designs.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-04-21T11:33:43-04:00">
  
  <meta property="article:modified_time" content="2020-04-21T11:33:43-04:00">
  

  

  

  
  <title> FPGA programming for the rest of us | Rachit Nigam </title>
  

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="../../">Rachit Nigam</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="../../resume.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">FPGA programming for the rest of us</h1>

    

<div class="article-metadata">

  

  <span class="article-date">
    
    <meta content="2020-04-21 11:33:43 -0400 -0400" itemprop="datePublished">
    <time datetime="2020-04-21 11:33:43 -0400 -0400" itemprop="dateModified">
      Apr 21, 2020
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  

  

  
  

  

</div>


    <div class="article-style" itemprop="articleBody">
      

<p><strong>THIS IS A DRAFT POST. DO NOT DISTRIBUTE.</strong></p>

<blockquote>
<p>This is quick overview of my research on <a href="../../publication/dahlia">Dahlia</a>, a
new programming language that leverages sub-structural types to make hardware
design predictable.</p>
</blockquote>

<p>This blog post assumes some familiarity with reconfigurable architectures and
High-Level Synthesis. If you want a quick overview on those, check out my
blog post on <a href="../../post/reconf-future">compiling for the reconfigurable future</a>.</p>

<p>High-Level Synthesis (HLS) is the idea of transforming functional descriptions
of programs into performant and efficient hardware designs. The productivity
and accessibility benefits of raising the level of abstraction are remarkable.
For example, here is how you can implement a simple dot-product accelerator
(eliding some wrapper code required to generate communication interfaces):</p>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="kt">int</span> <span class="nf">mv_mult</span><span class="p">(</span><span class="kt">int</span> <span class="n">v1</span><span class="p">[</span><span class="mi">32</span><span class="p">],</span> <span class="kt">int</span> <span class="n">v2</span><span class="p">[</span><span class="mi">32</span><span class="p">])</span> <span class="p">{</span>
  <span class="kt">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="mi">32</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="n">sum</span> <span class="o">+=</span> <span class="n">v1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">v2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">sum</span><span class="p">;</span>
<span class="p">}</span></code></pre></div>
<p>We have managed to implement a full accelerator in less than ten lines of code!
The HLS compiler will automatically generate the communication interfaces and
the required hardware modules. Owing to its incredible promise of rapid
iterative design, HLS tools are often marketed to software engineers.</p>

<p>Unfortunately, building <em>performant</em> designs in HLS is not as simple as writing
a dot-product accelerator. HLS tools use an incredible array of <a href="https://dl.acm.org/doi/10.1145/1146909.1147025" rel="noreferrer" target="_blank">analyses</a>
and program transformations to generate efficient hardware. Add to this
closed source tools and long compilation cycles, we end up with black box tools that
fail to provide feedback when things go wrong. In order to force HLS to generate
desired hardware, HLS users often end up writing convoluted code that can
direct the compiler into making desired choices.</p>

<p>Instead of performing code gymnastics, HLS programming models should provide
a principled mechanism to control various aspects, such as timing and resource
sharing, of the generated hardware.</p>

<h3 id="pitfalls-of-hls">Pitfalls of HLS</h3>

<p>Let&rsquo;s walk through a short example to demonstrate the failings of HLS tools.<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>We begin with everyone&rsquo;s favorite kernel, General Matrix-Matrix Multiply (GeMM).
There are three good reasons to start by building a GeMM accelerator:</p>

<ol>
<li>Along with convolution, GeMM forms the foundation of modern ML.</li>
<li>The kernel has a lot of inherent parallelism.</li>
<li>We already know how to build good GeMM accelerators by hand.</li>
</ol>

<p>The HLS implementation for GeMM is straightforward:</p>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="kt">int</span> <span class="n">m1</span><span class="p">[</span><span class="mi">512</span><span class="p">][</span><span class="mi">512</span><span class="p">],</span> <span class="n">m2</span><span class="p">[</span><span class="mi">512</span><span class="p">][</span><span class="mi">512</span><span class="p">],</span> <span class="n">prod</span><span class="p">[</span><span class="mi">512</span><span class="p">][</span><span class="mi">512</span><span class="p">],</span> <span class="n">sum</span><span class="p">;</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">512</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="mi">512</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">512</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
      <span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="n">prod</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></div>
<p>The program looks like any GeMM implementation you&rsquo;d expect to see in a freshmen
level course. HLS is particularly good at synthesizing such compute-heavy
loop-nests. The generated FPGA design is pretty reasonable&mdash;it computes the
matrix product in 841ms, or about 10x faster than the same code running on
a CPU. The design occupies 2,355 of the FPGA&rsquo;s lookup tables (LUTs). Remember
these two metrics: runtime and area (correlated to the number of LUTs) since
they are the primary objectives in a hardware design. Accelerator
design is all about maximizing this trade-off: An ideal hardware design
takes as little area as possible while running as fast as possible.</p>

<p>Having a functional design isn&rsquo;t sufficient. Next, we&rsquo;d like to trade-off
area for runtime. The FPGA has well over a million LUTs and we&rsquo;d like to
expend more area to get performance benefits. A straightforward way of
parallelizing the GeMM kernel is by running copies of the innermost loop in
parallel. HLS tools provide pragmas (or C annotations) that can tell the compiler
to duplicate a loop body:</p>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">512</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="cp">#pragma HLS unroll factor=8
</span><span class="cp"></span>  <span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
<span class="p">}</span></code></pre></div>
<p>The <code>#pragma</code> states that the innermost loop should run 8 copies in parallel
by <em>unrolling</em> the loop. Logically, this is the same as:</p>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">k</span> <span class="o">&lt;</span> <span class="mi">64</span><span class="p">;</span> <span class="n">k</span><span class="o">+=</span><span class="mi">8</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
  <span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
  <span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
  <span class="p">...</span>
  <span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">7</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">7</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
<span class="p">}</span></code></pre></div>
<p>where each statement in the loop body runs in parallel. Since we&rsquo;re trading off
area for runtim, we should do our due diligence and make an <em>area-runtime</em>
plot to see how spending more area improves our runtime. Since we&rsquo;re performing
many computations in parallel, we expect our area numbers to go up while the
runtime numbers go down.</p>

<div class='row'>
<div class='col-sm-6'>
<img src="../../img/no-partition-unrolling-runtime-avg.png"
     alt="Runtime (ms) when unrolling innermost without any partitioning"/>
</div>
<div class='col-sm-6'>
<img src="../../img/no-partition-unrolling-lut-used.png"
     alt="LUTs used when unrolling innermost without any partitioning"/>
</div>
</div>
<div class='row'>
<center>
</center>
</div>

<p>These numbers look odd. Our area seems to roughly increase as we increase the
unrolling factor but our runtime is all over the place. What is going on?</p>

<p><strong>On Physical Memories</strong></p>

<p>Real memory, much like the rest of a processor, is a physical circuit with
constraints on when and where it can process read and write requests. Modern
processors make it really easy and cheap to randomly access memory addresses
by using multiple levels of caches. FPGAs on the other hand expose memories
with a very low-level interface&ndash;each memory is only allowed to read/write one
value every clock cycle.<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup></p>

<p>Given this one read/write per cycle restriction, let&rsquo;s think what our hardware
design is trying to do:</p>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
<span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
<span class="n">sum</span> <span class="o">+=</span> <span class="n">m1</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">m2</span><span class="p">[</span><span class="n">k</span> <span class="o">+</span> <span class="mi">2</span><span class="p">][</span><span class="n">j</span><span class="p">];</span></code></pre></div>
<p>Each one of these statements try to access a unique address in <code>m1</code> and <code>m2</code>.
This means, that each clock cycle, memories <code>m1</code> and <code>m2</code> get <strong>8 read
requests</strong> while being able to only service one request a cycle. HLS compilers
statically detect conflicting accesses and <em>stall</em> the parallel reads to the
memories. So even though we&rsquo;re spending area to create copies of our loop
body in the hardware, we don&rsquo;t get to see any performance benefits.</p>

<p>In order to get the performance benefits, we have to <em>partition</em> our memories.
A partitioned memory can be accessed as one logical entity but is backed by
several physical memories containing disjoint elements. HLS tools can partition
memories using the partition pragma:</p>
<div class="highlight"><pre class="chroma"><code class="language-C" data-lang="C"><span class="cp">#pragma HLS ARRAY_PARTITION VARIABLE=m1 FACTOR=8
</span><span class="cp"></span><span class="kt">int</span> <span class="n">m1</span><span class="p">[</span><span class="mi">512</span><span class="p">][</span><span class="mi">512</span><span class="p">];</span></code></pre></div>
<p>A memory partitioned by a factor of 8 is supported by 8 physical banks, each
containing a disjoint set of elements from the original array. Now that
our memories can support up to 8 parallel reads/writes, let&rsquo;s see what our
graphs look like:</p>

<div class='row'>
<div class='col-sm-6'>
<img src="../../img/const-partition-unroll-runtime-avg.png"
     alt="Runtime (ms) when unrolling innermost with partitioning = 8"/>
</div>
<div class='col-sm-6'>
<img src="../../img/const-partition-unroll-lut-used.png"
     alt="LUTs used when unrolling innermost with partitioning = 8"/>
</div>
</div>
<div class='row'>
<center>
</center>
</div>

<p>Once again, the rough area trend goes up but the runtime numbers are still
all over the place. What&rsquo;s worse, some of the unrolling factors seem to now
generate <em>invalid hardware designs</em>.</p>

<p><strong>TODO: explain this result.</strong></p>

<h3 id="a-little-bit-of-pl-magic">A Little Bit of PL magic</h3>

<p>The fundamental problem here is that FPGA designs use <em>physical resources</em>
without reasoning about their constraints. The HLS tools will happily generate
hardware for configurations that produce worse area and runtime numbers. Is
HLS a fundamentally a bad idea?</p>

<p>I argue that beneath the mess of weird semantics and unpredictable behavior,
there is a reasonable programming model. The promise of HLS&mdash;to make FPGA
programming accessible to us measly software programmers&mdash;is an ambitious
goal and stands to truly revolutionize how we design heterogeneous systems.
Instead of giving up on the idea, perhaps we can separate out its successes
from its failures.</p>

<h3 id="p-stands-for-predictable">P stands for Predictable</h3>

<p>In our <a href="../../files/pubs/dahlia.pdf">paper</a>, we identified <em>predictability</em> as a central goal
for HLS compilers. However, predictability is a subjective term&mdash;as a reviewer
was quick to point out, &ldquo;what is and isn&rsquo;t predictable is matter of training,
background, documentation and support.&rdquo; The examples above might make perfect
sense to a hardware designer&mdash;after all, they are well versed with the
restrictions of physical memories. On the other hand, an experienced C++
programmer might find the above graphs totally baffling. We identified
area-latency trade-offs as the central predictability problem in HLS.
For us, predictability can be summarized as &ldquo;If I spend more area, I get better
performance.&rdquo;</p>

<p><em>Have comments? <a href="mailto:rachit.nigam12@gmail.com" rel="noreferrer" target="_blank">Email</a> or <a href="https://twitter.com/notypes" rel="noreferrer" target="_blank">tweet</a> at me.</em></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1">The presented results use real data from synthesizing and running FPGA designs using <a href="https://www.xilinx.com/products/design-tools/vivado/integration/esl-design.html" rel="noreferrer" target="_blank">Vivado HLS</a> on <a href="https://aws.amazon.com/ec2/instance-types/f1/" rel="noreferrer" target="_blank">AWS F1</a> instances. Check out <a href="../../files/pubs/dahlia.pdf">our paper</a> for full details.
 <a class="footnote-return" href="#fnref:1"><sup>↩</sup></a></li>
<li id="fn:2">Real FPGA memories are slightly more complicated because they have several <em>memory ports</em>. Each memory port allows one read/write every clock cycle.
 <a class="footnote-return" href="#fnref:2"><sup>↩</sup></a></li>
</ol>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline"
     href="../../tags/high-level-synthesis/">
     high-level synthesis
  </a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="../../post/reconf-future/">Compiling for the Reconfigurable Future</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy;&nbsp;Rachit Nigam 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>

    
    

  </body>
</html>

