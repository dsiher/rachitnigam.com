<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.49.2" />
  

  
  
  
  
    
      
    
  
  <meta name="description" content="A TLDR on why you should care. FPGAs, a form of reconfigurable architectures, already power a large number of datacenter applications. With FPGA acceleration becoming mainstream, it is the perfect opportunity to think about programming models for designing next-generation high-performance hardware.
 Moore&rsquo;s law is in its death throes. With Global Foundries announcing that they are no longer pursuing 7nm production nodes, fabrication companies focusing on incremental improvements, and the end of the arguably more important Dennard scaling, we&rsquo;re entering a new era where general purpose architectures are no longer the solution.">

  
  <link rel="alternate" hreflang="en-us" href="../../post/reconf-future/">

  


  

  
  
  <meta name="theme-color" content="#000">
  

  <link rel="stylesheet" href="../../css/bootstrap.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="../../styles.css">
  
  <link rel="stylesheet" href="../../css/syntax.css">
  

  
  <link rel="alternate" href="../../index.xml" type="application/rss+xml" title="Rachit Nigam">
  <link rel="feed" href="../../index.xml" type="application/rss+xml" title="Rachit Nigam">
  

  <link rel="manifest" href="../../site.webmanifest">
  <link rel="icon" type="image/png" href="../../img/dusk-asterisk.png">
  

  <link rel="canonical" href="https://rachitnigam.com">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@notypes">
  <meta property="twitter:creator" content="@notypes">
  
  <meta property="og:site_name" content="Rachit Nigam">
  <meta property="og:url" content="/post/reconf-future/">
  <meta property="og:title" content="Compiling for the Reconfigurable Future | Rachit Nigam">
  <meta property="og:description" content="A TLDR on why you should care. FPGAs, a form of reconfigurable architectures, already power a large number of datacenter applications. With FPGA acceleration becoming mainstream, it is the perfect opportunity to think about programming models for designing next-generation high-performance hardware.
 Moore&rsquo;s law is in its death throes. With Global Foundries announcing that they are no longer pursuing 7nm production nodes, fabrication companies focusing on incremental improvements, and the end of the arguably more important Dennard scaling, we&rsquo;re entering a new era where general purpose architectures are no longer the solution.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2020-04-16T11:59:11-04:00">
  
  <meta property="article:modified_time" content="2020-04-16T11:59:11-04:00">
  

  

  

  
  <title> Compiling for the Reconfigurable Future | Rachit Nigam </title>
  

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="../../">Rachit Nigam</a>
      <a class="navbar-brand navbar-center" href="https://blacklivesmatter.com/">
      <img src="../../img/blm.png" alt="Black Lives Matter"/>
      </a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a href="../../#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a href="../../#publications_selected">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a href="../../#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a href="../../resume.pdf">
            
            <span>CV</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Compiling for the Reconfigurable Future</h1>

    

<div class="article-metadata">

  

  <span class="article-date">
    
    <meta content="2020-04-16 11:59:11 -0400 -0400" itemprop="datePublished">
    <time datetime="2020-04-16 11:59:11 -0400 -0400" itemprop="dateModified">
      Apr 16, 2020
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    7 min read
  </span>
  

  
  

  

  
  

  

</div>


    <div class="article-style" itemprop="articleBody">
      

<blockquote>
<p><strong>A TLDR on why you should care.</strong> FPGAs, a form of reconfigurable
architectures, already power a large number of datacenter applications. With
FPGA acceleration becoming mainstream, it is the perfect opportunity to think
about programming models for designing next-generation high-performance
hardware.</p>
</blockquote>

<p>Moore&rsquo;s law is in its death throes. With Global Foundries <a href="https://www.anandtech.com/show/13277/globalfoundries-stops-all-7nm-development" rel="noreferrer" target="_blank">announcing</a>
that they are no longer pursuing 7nm production nodes, fabrication companies
focusing on <a href="https://www.anandtech.com/show/15217/intels-manufacturing-roadmap-from-2019-to-2029" rel="noreferrer" target="_blank">incremental improvements</a>, and the end of the
arguably more important <a href="https://en.wikipedia.org/wiki/Dennard_scaling" rel="noreferrer" target="_blank">Dennard scaling</a>, we&rsquo;re entering a new
era where general purpose architectures are no longer the solution.
Reconfigurable architectures are one of the hottest research topics and perhaps
hold the key to application-specific hardware acceleration. However, without
a sane programming model, reconfigurable architectures might not achieve the
success they deserve.</p>

<h3 id="reconfigurable-architectures">Reconfigurable Architectures</h3>

<p>Since the dawn of computer architecture, we&rsquo;ve focused on building processors
that are good at executing <em>every</em> conceivable program. The advances in
pipelined designs, speculative and out-of-order execution all try to
dynamically discover regularity and parallelism in arbitrary programs and
execute them as fast as possible. The performance benefits of these technologies
are inarguable. However, all good things come at a price. In their
single-minded zealotry to improve single threaded performance, processors introduce
an incredible amount of <em>control overhead</em>. Figure 1 shows the energy
breakdown of executing an add instruction. The control dominates the cost of
executing an instruction.</p>

<p><center>
<figure>
<img src="../../img/energy-breakdown.png"
     alt="Energy breakdown of executing an add instruction on 45nm technology.">
</img>
<figcaption>
Fig 1.
Energy breakdown of executing an add instruction from
&ldquo;<a href="https://ieeexplore.ieee.org/document/6757323" rel="noreferrer" target="_blank">Computing&rsquo;s Energy Problem</a>&rdquo; [Horowitz, 2014].
</figcaption>
</figure>
</center></p>

<p>So while modern processors
can execute arbitrary programs quickly, they leave a lot of room for improvement
with an individual program.
Instead of paying for the cost of the general control structures in every program,
what if your processor could pay for the exactly the amount of control required
to execute the current program.
What if you
could <em>reconfigure</em> your architecture
based on the currently executing program?
Reconfigurable architectures refers to the general class of architectures
that allow some degree of application-specific reconfigurability. The term
&ldquo;reconfigurable architectures&rdquo; is incredibly broad and spans everything from
the reconfigurability of meshes in <a href="http://opencelerity.org/" rel="noreferrer" target="_blank">massive many-cores</a> to bit-level
reconfigurable architectures. In this post, we&rsquo;ll be focusing on Field
Programmable Gate Arrays (FPGAs) as a reconfigurable accelerator.</p>

<h3 id="fpgas-as-computational-accelerators">FPGAs as Computational Accelerators</h3>

<p>FPGAs were initially developed as high-performance simulators for circuit
designs. Testing a hardware design requires simulating its behavior over
thousands of clock cycles. With larger and more complex, the computational
power required to simulate and track the state of a design becomes increasingly
hard. Unfortunately, simulating a hardware design on a traditional processor
does not scale&mdash;imagine trying to simulate an i3
processor on a Pentium 4. FPGAs were designed as simulation accelerators. They
provide <em>bit-level</em> reconfigurability which allows them to simulate wires and
gates in a hardware design.</p>

<p>The bit-level reconfigurability also made FPGAs
viable as a cheaper, low-volume alternate to application specific integrated
circuits (ASICs). Instead of taping-out custom chips, FPGAs could be used to
prototype and integrate such accelerators without paying for a full
silicon tape-out. In domains like
signal processing or networking, where real-time deadlines really matter and
CPUs struggle to meet high-throughput requirements, FPGAs were successfully
used as computational accelerators. The common thread in all of these use cases
is that we really want to design custom circuits but don&rsquo;t want to pay the
costs of producing a whole new chip.</p>

<p>FPGAs happily chugged along in these niche roles for a long time without taking
off in a big way. Researchers knew that FPGAs could play a big role as flexible
accelerators but didn&rsquo;t have a &ldquo;killer app&rdquo;. Between 2010-2016, an exceptional
team of computer architects demonstrated
that FPGAs could be used as
computational accelerators <em>inside datacenters</em> through the <a href="https://www.microsoft.com/en-us/research/project/project-catapult/" rel="noreferrer" target="_blank">Catapult</a>
project. Catapult, and its successor <a href="https://www.microsoft.com/en-us/research/project/project-brainwave/" rel="noreferrer" target="_blank">BrainWave</a>, showed that not only can
FPGAs significantly improve the performance of modern large-scale applications,
they provide enough flexibility to be used in multiple domains, accelerating
everything from Bing search, Azure cloud network, and most recently, ML models.</p>

<p>Other cloud services like AWS have jumped on this trend and now offer <a href="https://aws.amazon.com/education/F1-instances-for-educators/" rel="noreferrer" target="_blank">F1
instances</a> which provide access to high-end FPGA units through AWS&rsquo;s
pay-what-you-use model.</p>

<h3 id="fpga-programming-101">FPGA Programming 101</h3>

<p>Owing to its root as a hardware simulator, FPGA programming toolchains repurpose
existing hardware design languages (HDLs). As a circuit simulator, this is
a really good idea. You can simply take your preexisting hardware design and
run it on an FPGA.<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">1</a></sup></p>

<p>Unfortunately, when trying to run high-level application code
the level of abstraction afforded by HDLs is far too low-level.
Imagine
trying to write a convolution kernel by specifying every wire connection
into every adder and the computation that occurs at every clock cycle. Proponents
of HDLs will point out that we can eek out every bit of performance from a
low-level hardware design. However, this also means that design iteration times
are much worse. It can take many weeks of engineering effort to implement
and optimize a design.</p>

<p>I am by no means the first person to point this productivity-performance
trade-off. Practitioners and researchers have created a multitude of
HDLs to improve the level of abstraction: <a href="https://bluespec.com/" rel="noreferrer" target="_blank">BlueSpec</a>, <a href="https://en.wikipedia.org/wiki/SystemVerilog" rel="noreferrer" target="_blank">SystemVerilog</a>, <a href="https://github.com/cornell-brg/pymtl3" rel="noreferrer" target="_blank">PyMTL</a>,
<a href="https://www.chisel-lang.org/" rel="noreferrer" target="_blank">Chisel</a>, etc. all aim to use host languages to improve the level of abstraction
in some manner. For example, Chisel is embedded in Scala and provides
modularity and parameterization mechanisms using Scala&rsquo;s type system.
However, HDLs still <em>fundamentally</em> operate at the gate-and-wire
level of abstraction. Chisel designs, after being typechecked by the Scala
compiler, are expanded into a structural specification of the hardware design.</p>

<p>A more radical technique to lift the level of abstraction would be to specify
<em>how</em> the computation occurs and use a compiler to generate the hardware for
that specification. The architecture community has been exploring the idea
of transforming behavioral (or functional) descriptions of computation
into hardware designs. This is commonly referred to High-Level Synthesis (HLS)
in the community.</p>

<h3 id="high-level-synthesis">High-Level Synthesis</h3>

<p>High-Level Synthesis<sup class="footnote-ref" id="fnref:3"><a href="#fn:3">2</a></sup> is the idea of compiling a computational description
in a high-level programming language<sup class="footnote-ref" id="fnref:4"><a href="#fn:4">3</a></sup>, like C or C++, into an HDL like
Verilog. HLS has been quite successful in a multitude of domains&mdash;everything
from <a href="https://ieeexplore.ieee.org/document/1466178" rel="noreferrer" target="_blank">digital signal processing</a> to <a href="https://dl.acm.org/doi/10.1145/3020078.3021741" rel="noreferrer" target="_blank">machine learning
accelerators</a> has been implemented in HLS.</p>

<p>The semantic gap between a functional description and timed hardware structures
is quite large. Hardware designs are <em>timed</em> because they explicitly describe
the
behavior of individual circuits at the granularity of clock cycles. An HLS
compiler needs to transform the functional description into a <em>data path</em>,
which describes the hardware structures that perform computations, and
a <em>control path</em>, which describes the computation performed by components every
cycle.</p>

<p>The promise of transforming <em>any</em> C++ program into hardware is absurd at its
face. C++ programs dynamically allocate memory, use complicated control
structures, and are notoriously hard to analyze. Compare this to physical
hardware where memory sizes and control structures need to statically generated
at compile time.</p>

<p>I&rsquo;ll leave the specifics of where HLS fails for a future blog post. If you&rsquo;re
curious, dive into <a href="../../files/pubs/dahlia.pdf">our paper</a> on <a href="https://capra.cs.cornell.edu/dahlia" rel="noreferrer" target="_blank">Dahlia</a> which identifies
some of these problems and shows how little bit of programming languages magic
can help.</p>

<p>If you&rsquo;re curious about this area, jump onto these cool blog posts and papers:</p>

<ul>
<li><a href="https://www.cs.cornell.edu/~asampson/blog/fpgaabstraction.html" rel="noreferrer" target="_blank">FPGAs Have the Wrong Abstraction</a> by Adrian Sampson.</li>
<li><a href="https://ieeexplore.ieee.org/document/5737854?tp=&amp;arnumber=5737854" rel="noreferrer" target="_blank">High-Level Synthesis for FPGAs: From Prototyping to Development</a>.</li>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/Cloud-Scale-Acceleration-Architecture.pdf" rel="noreferrer" target="_blank">A Cloud-Scale Acceleration Architecture</a>.</li>
</ul>

<p>(If you&rsquo;ve written a blog post on HLS-related stuff, email it to me so I can
add it here!)</p>

<p><em>Thanks for <a href="http://adriansampson.net" rel="noreferrer" target="_blank">Adrian Sampson</a> and <a href="https://www.cs.cornell.edu/~avh/" rel="noreferrer" target="_blank">Alexa VanHattum</a> for providing feedback on early
drafts of this blog post</em>.</p>

<p><em>Have comments? <a href="mailto:rachit.nigam12@gmail.com" rel="noreferrer" target="_blank">Email</a> or <a href="https://twitter.com/notypes" rel="noreferrer" target="_blank">tweet</a> at me.</em></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:2">I apologize to my architect friends. Running designs on an FPGA in reality can be an incredible challenge. FPGAs have different kinds of memory and performance characteristics. Most hardware design codebases are carefully engineered to separate FPGA-specific design decisions from the core design.
 <a class="footnote-return" href="#fnref:2"><sup>↩</sup></a></li>
<li id="fn:3">Architects adopted the &ldquo;Synthesis&rdquo; terminology from hardware design workflows. A hardware design is <em>synthesized</em> into silicon. Since we&rsquo;re now generating designs from a high-level language, we&rsquo;ll call it &ldquo;High-level Synthesis&rdquo;. From a compiler/programming languages viewpoint, this is just a compiler.
 <a class="footnote-return" href="#fnref:3"><sup>↩</sup></a></li>
<li id="fn:4">The choice of C or C++ as a &ldquo;high-level language&rdquo; might seem odd but to architects, who operate at the level clock cycles and hardware structures, C++ is a huge jump in abstraction.
 <a class="footnote-return" href="#fnref:4"><sup>↩</sup></a></li>
</ol>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline"
     href="../../tags/high-level-synthesis/">
     high-level synthesis
  </a>
  
</div>




    
    

    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy;&nbsp;Rachit Nigam 2018 &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>

    
    

  </body>
</html>

